ok: class CLASS ::.Features2d : , name: Features2d, base: 

===== Common header : /home/jeon/다운로드/opencv-3.4.0/modules/features2d/misc/java/src/cpp/features2d_converters.hpp =====


===== Header: /home/jeon/다운로드/opencv-3.4.0/modules/features2d/misc/java/src/cpp/features2d_manual.hpp =====
Namespaces: set([u'cv'])

--- Incoming ---
[   u'class cv.javaFeatureDetector',
    '',
    [u'=FeatureDetector'],
    [],
    None,
    u'* @deprecated Please use direct instantiation of Feature2D classes']
docstring: * @deprecated Please use direct instantiation of Feature2D classes
ok: class CLASS cv::.javaFeatureDetector : , name: javaFeatureDetector, base: 

--- Incoming ---
[   u'cv.javaFeatureDetector.detect',
    u'void',
    ['/C'],
    [   [u'Mat', u'image', u'', ['/C', '/Ref']],
        [u'vector_KeyPoint', u'keypoints', u'', ['/O', '/Ref']],
        [u'Mat', u'mask', u'Mat()', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaFeatureDetector.detect [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat mask=Mat()]>

--- Incoming ---
[   u'cv.javaFeatureDetector.detect',
    u'void',
    ['/C'],
    [   [u'vector_Mat', u'images', u'', ['/C', '/Ref']],
        [u'vector_vector_KeyPoint', u'keypoints', u'', ['/O', '/Ref']],
        [u'vector_Mat', u'masks', u'std::vector<Mat>()', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaFeatureDetector.detect [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat masks=std::vector<Mat>()]>

--- Incoming ---
[u'cv.javaFeatureDetector.empty', u'bool', ['/C'], [], u'bool', '']
ok: FUNC <bool cv.javaFeatureDetector.empty []>

--- Incoming ---
[u'const cv.javaFeatureDetector.FAST', u'1', [], [], None, '']
ok: CONST FAST=1

--- Incoming ---
[u'const cv.javaFeatureDetector.STAR', u'2', [], [], None, '']
ok: CONST STAR=2

--- Incoming ---
[u'const cv.javaFeatureDetector.SIFT', u'3', [], [], None, '']
ok: CONST SIFT=3

--- Incoming ---
[u'const cv.javaFeatureDetector.SURF', u'4', [], [], None, '']
ok: CONST SURF=4

--- Incoming ---
[u'const cv.javaFeatureDetector.ORB', u'5', [], [], None, '']
ok: CONST ORB=5

--- Incoming ---
[u'const cv.javaFeatureDetector.MSER', u'6', [], [], None, '']
ok: CONST MSER=6

--- Incoming ---
[u'const cv.javaFeatureDetector.GFTT', u'7', [], [], None, '']
ok: CONST GFTT=7

--- Incoming ---
[u'const cv.javaFeatureDetector.HARRIS', u'8', [], [], None, '']
ok: CONST HARRIS=8

--- Incoming ---
[u'const cv.javaFeatureDetector.SIMPLEBLOB', u'9', [], [], None, '']
ok: CONST SIMPLEBLOB=9

--- Incoming ---
[u'const cv.javaFeatureDetector.DENSE', u'10', [], [], None, '']
ok: CONST DENSE=10

--- Incoming ---
[u'const cv.javaFeatureDetector.BRISK', u'11', [], [], None, '']
ok: CONST BRISK=11

--- Incoming ---
[u'const cv.javaFeatureDetector.AKAZE', u'12', [], [], None, '']
ok: CONST AKAZE=12

--- Incoming ---
[u'const cv.javaFeatureDetector.GRIDDETECTOR', u'1000', [], [], None, '']
ok: CONST GRIDDETECTOR=1000

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_FAST',
    u'GRIDDETECTOR + FAST',
    [],
    [],
    None,
    '']
ok: CONST GRID_FAST=GRIDDETECTOR + FAST

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_STAR',
    u'GRIDDETECTOR + STAR',
    [],
    [],
    None,
    '']
ok: CONST GRID_STAR=GRIDDETECTOR + STAR

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_SIFT',
    u'GRIDDETECTOR + SIFT',
    [],
    [],
    None,
    '']
ok: CONST GRID_SIFT=GRIDDETECTOR + SIFT

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_SURF',
    u'GRIDDETECTOR + SURF',
    [],
    [],
    None,
    '']
ok: CONST GRID_SURF=GRIDDETECTOR + SURF

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_ORB',
    u'GRIDDETECTOR + ORB',
    [],
    [],
    None,
    '']
ok: CONST GRID_ORB=GRIDDETECTOR + ORB

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_MSER',
    u'GRIDDETECTOR + MSER',
    [],
    [],
    None,
    '']
ok: CONST GRID_MSER=GRIDDETECTOR + MSER

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_GFTT',
    u'GRIDDETECTOR + GFTT',
    [],
    [],
    None,
    '']
ok: CONST GRID_GFTT=GRIDDETECTOR + GFTT

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_HARRIS',
    u'GRIDDETECTOR + HARRIS',
    [],
    [],
    None,
    '']
ok: CONST GRID_HARRIS=GRIDDETECTOR + HARRIS

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_SIMPLEBLOB',
    u'GRIDDETECTOR + SIMPLEBLOB',
    [],
    [],
    None,
    '']
ok: CONST GRID_SIMPLEBLOB=GRIDDETECTOR + SIMPLEBLOB

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_DENSE',
    u'GRIDDETECTOR + DENSE',
    [],
    [],
    None,
    '']
ok: CONST GRID_DENSE=GRIDDETECTOR + DENSE

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_BRISK',
    u'GRIDDETECTOR + BRISK',
    [],
    [],
    None,
    '']
ok: CONST GRID_BRISK=GRIDDETECTOR + BRISK

--- Incoming ---
[   u'const cv.javaFeatureDetector.GRID_AKAZE',
    u'GRIDDETECTOR + AKAZE',
    [],
    [],
    None,
    '']
ok: CONST GRID_AKAZE=GRIDDETECTOR + AKAZE

--- Incoming ---
[u'const cv.javaFeatureDetector.PYRAMIDDETECTOR', u'2000', [], [], None, '']
ok: CONST PYRAMIDDETECTOR=2000

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_FAST',
    u'PYRAMIDDETECTOR + FAST',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_FAST=PYRAMIDDETECTOR + FAST

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_STAR',
    u'PYRAMIDDETECTOR + STAR',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_STAR=PYRAMIDDETECTOR + STAR

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_SIFT',
    u'PYRAMIDDETECTOR + SIFT',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_SIFT=PYRAMIDDETECTOR + SIFT

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_SURF',
    u'PYRAMIDDETECTOR + SURF',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_SURF=PYRAMIDDETECTOR + SURF

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_ORB',
    u'PYRAMIDDETECTOR + ORB',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_ORB=PYRAMIDDETECTOR + ORB

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_MSER',
    u'PYRAMIDDETECTOR + MSER',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_MSER=PYRAMIDDETECTOR + MSER

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_GFTT',
    u'PYRAMIDDETECTOR + GFTT',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_GFTT=PYRAMIDDETECTOR + GFTT

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_HARRIS',
    u'PYRAMIDDETECTOR + HARRIS',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_HARRIS=PYRAMIDDETECTOR + HARRIS

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_SIMPLEBLOB',
    u'PYRAMIDDETECTOR + SIMPLEBLOB',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_SIMPLEBLOB=PYRAMIDDETECTOR + SIMPLEBLOB

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_DENSE',
    u'PYRAMIDDETECTOR + DENSE',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_DENSE=PYRAMIDDETECTOR + DENSE

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_BRISK',
    u'PYRAMIDDETECTOR + BRISK',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_BRISK=PYRAMIDDETECTOR + BRISK

--- Incoming ---
[   u'const cv.javaFeatureDetector.PYRAMID_AKAZE',
    u'PYRAMIDDETECTOR + AKAZE',
    [],
    [],
    None,
    '']
ok: CONST PYRAMID_AKAZE=PYRAMIDDETECTOR + AKAZE

--- Incoming ---
[u'const cv.javaFeatureDetector.DYNAMICDETECTOR', u'3000', [], [], None, '']
ok: CONST DYNAMICDETECTOR=3000

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_FAST',
    u'DYNAMICDETECTOR + FAST',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_FAST=DYNAMICDETECTOR + FAST

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_STAR',
    u'DYNAMICDETECTOR + STAR',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_STAR=DYNAMICDETECTOR + STAR

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_SIFT',
    u'DYNAMICDETECTOR + SIFT',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_SIFT=DYNAMICDETECTOR + SIFT

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_SURF',
    u'DYNAMICDETECTOR + SURF',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_SURF=DYNAMICDETECTOR + SURF

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_ORB',
    u'DYNAMICDETECTOR + ORB',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_ORB=DYNAMICDETECTOR + ORB

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_MSER',
    u'DYNAMICDETECTOR + MSER',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_MSER=DYNAMICDETECTOR + MSER

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_GFTT',
    u'DYNAMICDETECTOR + GFTT',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_GFTT=DYNAMICDETECTOR + GFTT

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_HARRIS',
    u'DYNAMICDETECTOR + HARRIS',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_HARRIS=DYNAMICDETECTOR + HARRIS

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_SIMPLEBLOB',
    u'DYNAMICDETECTOR + SIMPLEBLOB',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_SIMPLEBLOB=DYNAMICDETECTOR + SIMPLEBLOB

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_DENSE',
    u'DYNAMICDETECTOR + DENSE',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_DENSE=DYNAMICDETECTOR + DENSE

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_BRISK',
    u'DYNAMICDETECTOR + BRISK',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_BRISK=DYNAMICDETECTOR + BRISK

--- Incoming ---
[   u'const cv.javaFeatureDetector.DYNAMIC_AKAZE',
    u'DYNAMICDETECTOR + AKAZE',
    [],
    [],
    None,
    '']
ok: CONST DYNAMIC_AKAZE=DYNAMICDETECTOR + AKAZE

--- Incoming ---
[   u'cv.javaFeatureDetector.create',
    u'Ptr_javaFeatureDetector',
    ['/S'],
    [[u'int', u'detectorType', u'', []]],
    u'Ptr<javaFeatureDetector>',
    u'* supported: FAST STAR SIFT SURF ORB MSER GFTT HARRIS BRISK AKAZE Grid(XXXX) Pyramid(XXXX) Dynamic(XXXX)\n* not supported: SimpleBlob, Dense\n* @deprecated']
docstring: * supported: FAST STAR SIFT SURF ORB MSER GFTT HARRIS BRISK AKAZE Grid(XXXX) Pyramid(XXXX) Dynamic(XXXX)
* not supported: SimpleBlob, Dense
* @deprecated
ok: FUNC <Ptr_javaFeatureDetector cv.javaFeatureDetector.create [ARG int detectorType=]>

--- Incoming ---
[   u'cv.javaFeatureDetector.write',
    u'void',
    ['/C'],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaFeatureDetector.write [ARG String fileName=]>

--- Incoming ---
[   u'cv.javaFeatureDetector.read',
    u'void',
    [],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaFeatureDetector.read [ARG String fileName=]>

--- Incoming ---
[   u'class cv.javaDescriptorExtractor',
    '',
    [u'=DescriptorExtractor'],
    [],
    None,
    u'* @deprecated']
docstring: * @deprecated
ok: class CLASS cv::.javaDescriptorExtractor : , name: javaDescriptorExtractor, base: 

--- Incoming ---
[   u'cv.javaDescriptorExtractor.compute',
    u'void',
    ['/C'],
    [   [u'Mat', u'image', u'', ['/C', '/Ref']],
        [u'vector_KeyPoint', u'keypoints', u'', ['/IO', '/Ref']],
        [u'Mat', u'descriptors', u'', ['/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaDescriptorExtractor.compute [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat descriptors=]>

--- Incoming ---
[   u'cv.javaDescriptorExtractor.compute',
    u'void',
    ['/C'],
    [   [u'vector_Mat', u'images', u'', ['/C', '/Ref']],
        [u'vector_vector_KeyPoint', u'keypoints', u'', ['/IO', '/Ref']],
        [u'vector_Mat', u'descriptors', u'', ['/O', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaDescriptorExtractor.compute [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat descriptors=]>

--- Incoming ---
[u'cv.javaDescriptorExtractor.descriptorSize', u'int', ['/C'], [], u'int', '']
ok: FUNC <int cv.javaDescriptorExtractor.descriptorSize []>

--- Incoming ---
[u'cv.javaDescriptorExtractor.descriptorType', u'int', ['/C'], [], u'int', '']
ok: FUNC <int cv.javaDescriptorExtractor.descriptorType []>

--- Incoming ---
[u'cv.javaDescriptorExtractor.empty', u'bool', ['/C'], [], u'bool', '']
ok: FUNC <bool cv.javaDescriptorExtractor.empty []>

--- Incoming ---
[u'const cv.javaDescriptorExtractor.SIFT', u'1', [], [], None, '']
ok: CONST SIFT=1

--- Incoming ---
[u'const cv.javaDescriptorExtractor.SURF', u'2', [], [], None, '']
ok: CONST SURF=2

--- Incoming ---
[u'const cv.javaDescriptorExtractor.ORB', u'3', [], [], None, '']
ok: CONST ORB=3

--- Incoming ---
[u'const cv.javaDescriptorExtractor.BRIEF', u'4', [], [], None, '']
ok: CONST BRIEF=4

--- Incoming ---
[u'const cv.javaDescriptorExtractor.BRISK', u'5', [], [], None, '']
ok: CONST BRISK=5

--- Incoming ---
[u'const cv.javaDescriptorExtractor.FREAK', u'6', [], [], None, '']
ok: CONST FREAK=6

--- Incoming ---
[u'const cv.javaDescriptorExtractor.AKAZE', u'7', [], [], None, '']
ok: CONST AKAZE=7

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENTEXTRACTOR',
    u'1000',
    [],
    [],
    None,
    '']
ok: CONST OPPONENTEXTRACTOR=1000

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_SIFT',
    u'OPPONENTEXTRACTOR + SIFT',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_SIFT=OPPONENTEXTRACTOR + SIFT

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_SURF',
    u'OPPONENTEXTRACTOR + SURF',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_SURF=OPPONENTEXTRACTOR + SURF

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_ORB',
    u'OPPONENTEXTRACTOR + ORB',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_ORB=OPPONENTEXTRACTOR + ORB

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_BRIEF',
    u'OPPONENTEXTRACTOR + BRIEF',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_BRIEF=OPPONENTEXTRACTOR + BRIEF

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_BRISK',
    u'OPPONENTEXTRACTOR + BRISK',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_BRISK=OPPONENTEXTRACTOR + BRISK

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_FREAK',
    u'OPPONENTEXTRACTOR + FREAK',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_FREAK=OPPONENTEXTRACTOR + FREAK

--- Incoming ---
[   u'const cv.javaDescriptorExtractor.OPPONENT_AKAZE',
    u'OPPONENTEXTRACTOR + AKAZE',
    [],
    [],
    None,
    '']
ok: CONST OPPONENT_AKAZE=OPPONENTEXTRACTOR + AKAZE

--- Incoming ---
[   u'cv.javaDescriptorExtractor.create',
    u'Ptr_javaDescriptorExtractor',
    ['/S'],
    [[u'int', u'extractorType', u'', []]],
    u'Ptr<javaDescriptorExtractor>',
    '']
ok: FUNC <Ptr_javaDescriptorExtractor cv.javaDescriptorExtractor.create [ARG int extractorType=]>

--- Incoming ---
[   u'cv.javaDescriptorExtractor.write',
    u'void',
    ['/C'],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaDescriptorExtractor.write [ARG String fileName=]>

--- Incoming ---
[   u'cv.javaDescriptorExtractor.read',
    u'void',
    [],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.javaDescriptorExtractor.read [ARG String fileName=]>

--- Incoming ---
[u'const cv.DRAW_OVER_OUTIMG', u'1', [], [], None, '']
ok: CONST DRAW_OVER_OUTIMG=1

--- Incoming ---
[u'const cv.NOT_DRAW_SINGLE_POINTS', u'2', [], [], None, '']
ok: CONST NOT_DRAW_SINGLE_POINTS=2

--- Incoming ---
[u'const cv.DRAW_RICH_KEYPOINTS', u'4', [], [], None, '']
ok: CONST DRAW_RICH_KEYPOINTS=4

--- Incoming ---
[   u'cv.drawMatches',
    u'void',
    [u'=drawMatches2'],
    [   [u'Mat', u'img1', u'', ['/C', '/Ref']],
        [u'vector_KeyPoint', u'keypoints1', u'', ['/C', '/Ref']],
        [u'Mat', u'img2', u'', ['/C', '/Ref']],
        [u'vector_KeyPoint', u'keypoints2', u'', ['/C', '/Ref']],
        [u'vector_vector_DMatch', u'matches1to2', u'', ['/C', '/Ref']],
        [u'Mat', u'outImg', u'', ['/Ref']],
        [u'Scalar', u'matchColor', u'Scalar::all(-1)', ['/C', '/Ref']],
        [u'Scalar', u'singlePointColor', u'Scalar::all(-1)', ['/C', '/Ref']],
        [   u'vector_vector_char',
            u'matchesMask',
            u'std::vector<std::vector<char> >()',
            ['/C', '/Ref']],
        [u'int', u'flags', u'0', []]],
    u'void',
    '']
ok: FUNC <void cv..drawMatches [ARG Mat img1=, ARG vector_KeyPoint keypoints1=, ARG Mat img2=, ARG vector_KeyPoint keypoints2=, ARG vector_vector_DMatch matches1to2=, ARG Mat outImg=, ARG Scalar matchColor=Scalar::all(-1), ARG Scalar singlePointColor=Scalar::all(-1), ARG vector_vector_char matchesMask=std::vector<std::vector<char> >(), ARG int flags=0]>


===== Header: /home/jeon/다운로드/opencv-3.4.0/modules/features2d/include/opencv2/features2d.hpp =====
Namespaces: set([u'cv'])

--- Incoming ---
[   u'class cv.Feature2D',
    ': cv::Algorithm',
    [],
    [],
    None,
    u'@brief Abstract base class for 2D image feature detectors and descriptor extractors']
docstring: @brief Abstract base class for 2D image feature detectors and descriptor extractors
ok: class CLASS cv::.Feature2D : Algorithm, name: Feature2D, base: Algorithm

--- Incoming ---
[   u'cv.Feature2D.detect',
    u'void',
    ['/V'],
    [   ['Mat', u'image', '', []],
        [u'vector_KeyPoint', u'keypoints', u'', ['/O', '/Ref']],
        ['Mat', u'mask', u'Mat()', []]],
    u'void',
    u'@brief Detects keypoints in an image (first variant) or image set (second variant).\n\n@param image Image.\n@param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\nof keypoints detected in images[i] .\n@param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\nmatrix with non-zero values in the region of interest.']
docstring: @brief Detects keypoints in an image (first variant) or image set (second variant).

@param image Image.
@param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set
of keypoints detected in images[i] .
@param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer
matrix with non-zero values in the region of interest.
ok: FUNC <void cv.Feature2D.detect [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat mask=Mat()]>

--- Incoming ---
[   u'cv.Feature2D.detect',
    u'void',
    ['/V'],
    [   ['vector_Mat', u'images', '', []],
        [u'vector_vector_KeyPoint', u'keypoints', u'', ['/O', '/Ref']],
        ['vector_Mat', u'masks', u'vector_Mat()', []]],
    u'void',
    u'@overload\n@param images Image set.\n@param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\nof keypoints detected in images[i] .\n@param masks Masks for each input image specifying where to look for keypoints (optional).\nmasks[i] is a mask for images[i].']
docstring: @overload
@param images Image set.
@param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set
of keypoints detected in images[i] .
@param masks Masks for each input image specifying where to look for keypoints (optional).
masks[i] is a mask for images[i].
ok: FUNC <void cv.Feature2D.detect [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat masks=vector_Mat()]>

--- Incoming ---
[   u'cv.Feature2D.compute',
    u'void',
    ['/V'],
    [   ['Mat', u'image', '', []],
        [u'vector_KeyPoint', u'keypoints', u'', ['/O', '/IO', '/Ref']],
        ['Mat', u'descriptors', '', ['/O']]],
    u'void',
    u'@brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n(second variant).\n\n@param image Image.\n@param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\ncomputed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\nwith several dominant orientations (for each orientation).\n@param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\ndescriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\ndescriptor for keypoint j-th keypoint.']
docstring: @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set
(second variant).

@param image Image.
@param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be
computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint
with several dominant orientations (for each orientation).
@param descriptors Computed descriptors. In the second variant of the method descriptors[i] are
descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the
descriptor for keypoint j-th keypoint.
ok: FUNC <void cv.Feature2D.compute [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat descriptors=]>

--- Incoming ---
[   u'cv.Feature2D.compute',
    u'void',
    ['/V'],
    [   ['vector_Mat', u'images', '', []],
        [u'vector_vector_KeyPoint', u'keypoints', u'', ['/O', '/IO', '/Ref']],
        ['vector_Mat', u'descriptors', '', ['/O']]],
    u'void',
    u'@overload\n\n@param images Image set.\n@param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\ncomputed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\nwith several dominant orientations (for each orientation).\n@param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\ndescriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\ndescriptor for keypoint j-th keypoint.']
docstring: @overload

@param images Image set.
@param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be
computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint
with several dominant orientations (for each orientation).
@param descriptors Computed descriptors. In the second variant of the method descriptors[i] are
descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the
descriptor for keypoint j-th keypoint.
ok: FUNC <void cv.Feature2D.compute [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat descriptors=]>

--- Incoming ---
[   u'cv.Feature2D.detectAndCompute',
    u'void',
    ['/V'],
    [   ['Mat', u'image', '', []],
        ['Mat', u'mask', '', []],
        [u'vector_KeyPoint', u'keypoints', u'', ['/O', '/Ref']],
        ['Mat', u'descriptors', '', ['/O']],
        [u'bool', u'useProvidedKeypoints', u'false', []]],
    u'void',
    u'Detects keypoints and computes the descriptors']
docstring: Detects keypoints and computes the descriptors
ok: FUNC <void cv.Feature2D.detectAndCompute [ARG Mat image=, ARG Mat mask=, ARG vector_KeyPoint keypoints=, ARG Mat descriptors=, ARG bool useProvidedKeypoints=false]>

--- Incoming ---
[u'cv.Feature2D.descriptorSize', u'int', ['/C', '/V'], [], u'int', '']
ok: FUNC <int cv.Feature2D.descriptorSize []>

--- Incoming ---
[u'cv.Feature2D.descriptorType', u'int', ['/C', '/V'], [], u'int', '']
ok: FUNC <int cv.Feature2D.descriptorType []>

--- Incoming ---
[u'cv.Feature2D.defaultNorm', u'int', ['/C', '/V'], [], u'int', '']
ok: FUNC <int cv.Feature2D.defaultNorm []>

--- Incoming ---
[   u'cv.Feature2D.write',
    u'void',
    ['/C'],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.Feature2D.write [ARG String fileName=]>

--- Incoming ---
[   u'cv.Feature2D.read',
    u'void',
    [],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.Feature2D.read [ARG String fileName=]>

--- Incoming ---
[   u'cv.Feature2D.read',
    u'void',
    ['/V'],
    [[u'FileNode', 'arg1', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.Feature2D.read [ARG FileNode arg1=]>

--- Incoming ---
[u'cv.Feature2D.empty', u'bool', ['/C', '/V'], [], u'bool', '']
ok: FUNC <bool cv.Feature2D.empty []>

--- Incoming ---
[u'cv.Feature2D.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.Feature2D.getDefaultName []>

--- Incoming ---
[   u'cv.Feature2D.write',
    u'void',
    ['/C'],
    [   [u'Ptr_FileStorage', u'fs', u'', ['/C', '/Ref']],
        [u'String', u'name', u'String()', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.Feature2D.write [ARG Ptr_FileStorage fs=, ARG String name=String()]>

--- Incoming ---
[   u'class cv.BRISK',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Class implementing the BRISK keypoint detector and descriptor extractor, described in @cite LCS11 .']
docstring: @brief Class implementing the BRISK keypoint detector and descriptor extractor, described in @cite LCS11 .
ok: class CLASS cv::.BRISK : Feature2D, name: BRISK, base: Feature2D

--- Incoming ---
[   u'cv.BRISK.create',
    u'Ptr_BRISK',
    ['/S'],
    [   [u'int', u'thresh', u'30', []],
        [u'int', u'octaves', u'3', []],
        [u'float', u'patternScale', u'1.0f', []]],
    u'Ptr<BRISK>',
    u'@brief The BRISK constructor\n\n@param thresh AGAST detection threshold score.\n@param octaves detection octaves. Use 0 to do single scale.\n@param patternScale apply this scale to the pattern used for sampling the neighbourhood of a\nkeypoint.']
docstring: @brief The BRISK constructor

@param thresh AGAST detection threshold score.
@param octaves detection octaves. Use 0 to do single scale.
@param patternScale apply this scale to the pattern used for sampling the neighbourhood of a
keypoint.
ok: FUNC <Ptr_BRISK cv.BRISK.create [ARG int thresh=30, ARG int octaves=3, ARG float patternScale=1.0f]>

--- Incoming ---
[   u'cv.BRISK.create',
    u'Ptr_BRISK',
    ['/S'],
    [   [u'vector_float', u'radiusList', u'', ['/C', '/Ref']],
        [u'vector_int', u'numberList', u'', ['/C', '/Ref']],
        [u'float', u'dMax', u'5.85f', []],
        [u'float', u'dMin', u'8.2f', []],
        [   u'vector_int',
            u'indexChange',
            u'std::vector<int>()',
            ['/C', '/Ref']]],
    u'Ptr<BRISK>',
    u'@brief The BRISK constructor for a custom pattern\n\n@param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\nkeypoint scale 1).\n@param numberList defines the number of sampling points on the sampling circle. Must be the same\nsize as radiusList..\n@param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\nscale 1).\n@param dMin threshold for the long pairings used for orientation determination (in pixels for\nkeypoint scale 1).\n@param indexChange index remapping of the bits.']
docstring: @brief The BRISK constructor for a custom pattern

@param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for
keypoint scale 1).
@param numberList defines the number of sampling points on the sampling circle. Must be the same
size as radiusList..
@param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint
scale 1).
@param dMin threshold for the long pairings used for orientation determination (in pixels for
keypoint scale 1).
@param indexChange index remapping of the bits.
ok: FUNC <Ptr_BRISK cv.BRISK.create [ARG vector_float radiusList=, ARG vector_int numberList=, ARG float dMax=5.85f, ARG float dMin=8.2f, ARG vector_int indexChange=std::vector<int>()]>

--- Incoming ---
[   u'cv.BRISK.create',
    u'Ptr_BRISK',
    ['/S'],
    [   [u'int', u'thresh', u'', []],
        [u'int', u'octaves', u'', []],
        [u'vector_float', u'radiusList', u'', ['/C', '/Ref']],
        [u'vector_int', u'numberList', u'', ['/C', '/Ref']],
        [u'float', u'dMax', u'5.85f', []],
        [u'float', u'dMin', u'8.2f', []],
        [   u'vector_int',
            u'indexChange',
            u'std::vector<int>()',
            ['/C', '/Ref']]],
    u'Ptr<BRISK>',
    u'@brief The BRISK constructor for a custom pattern, detection threshold and octaves\n\n@param thresh AGAST detection threshold score.\n@param octaves detection octaves. Use 0 to do single scale.\n@param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\nkeypoint scale 1).\n@param numberList defines the number of sampling points on the sampling circle. Must be the same\nsize as radiusList..\n@param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\nscale 1).\n@param dMin threshold for the long pairings used for orientation determination (in pixels for\nkeypoint scale 1).\n@param indexChange index remapping of the bits.']
docstring: @brief The BRISK constructor for a custom pattern, detection threshold and octaves

@param thresh AGAST detection threshold score.
@param octaves detection octaves. Use 0 to do single scale.
@param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for
keypoint scale 1).
@param numberList defines the number of sampling points on the sampling circle. Must be the same
size as radiusList..
@param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint
scale 1).
@param dMin threshold for the long pairings used for orientation determination (in pixels for
keypoint scale 1).
@param indexChange index remapping of the bits.
ok: FUNC <Ptr_BRISK cv.BRISK.create [ARG int thresh=, ARG int octaves=, ARG vector_float radiusList=, ARG vector_int numberList=, ARG float dMax=5.85f, ARG float dMin=8.2f, ARG vector_int indexChange=std::vector<int>()]>

--- Incoming ---
[u'cv.BRISK.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.BRISK.getDefaultName []>

--- Incoming ---
[   u'class cv.ORB',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Class implementing the ORB (*oriented BRIEF*) keypoint detector and descriptor extractor\n\ndescribed in @cite RRKB11 . The algorithm uses FAST in pyramids to detect stable keypoints, selects\nthe strongest features using FAST or Harris response, finds their orientation using first-order\nmoments and computes the descriptors using BRIEF (where the coordinates of random point pairs (or\nk-tuples) are rotated according to the measured orientation).']
docstring: @brief Class implementing the ORB (*oriented BRIEF*) keypoint detector and descriptor extractor

described in @cite RRKB11 . The algorithm uses FAST in pyramids to detect stable keypoints, selects
the strongest features using FAST or Harris response, finds their orientation using first-order
moments and computes the descriptors using BRIEF (where the coordinates of random point pairs (or
k-tuples) are rotated according to the measured orientation).
ok: class CLASS cv::.ORB : Feature2D, name: ORB, base: Feature2D

--- Incoming ---
[u'const cv.ORB.kBytes', u'32', [], [], None, '']
ok: CONST kBytes=32

--- Incoming ---
[u'const cv.ORB.HARRIS_SCORE', u'0', [], [], None, '']
ok: CONST HARRIS_SCORE=0

--- Incoming ---
[u'const cv.ORB.FAST_SCORE', u'1', [], [], None, '']
ok: CONST FAST_SCORE=1

--- Incoming ---
[   u'cv.ORB.create',
    u'Ptr_ORB',
    ['/S'],
    [   [u'int', u'nfeatures', u'500', []],
        [u'float', u'scaleFactor', u'1.2f', []],
        [u'int', u'nlevels', u'8', []],
        [u'int', u'edgeThreshold', u'31', []],
        [u'int', u'firstLevel', u'0', []],
        [u'int', u'WTA_K', u'2', []],
        [u'int', u'scoreType', u'ORB::HARRIS_SCORE', []],
        [u'int', u'patchSize', u'31', []],
        [u'int', u'fastThreshold', u'20', []]],
    u'Ptr<ORB>',
    u'@brief The ORB constructor\n\n@param nfeatures The maximum number of features to retain.\n@param scaleFactor Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical\npyramid, where each next level has 4x less pixels than the previous, but such a big scale factor\nwill degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor\nwill mean that to cover certain scale range you will need more pyramid levels and so the speed\nwill suffer.\n@param nlevels The number of pyramid levels. The smallest level will have linear size equal to\ninput_image_linear_size/pow(scaleFactor, nlevels).\n@param edgeThreshold This is size of the border where the features are not detected. It should\nroughly match the patchSize parameter.\n@param firstLevel It should be 0 in the current implementation.\n@param WTA_K The number of points that produce each element of the oriented BRIEF descriptor. The\ndefault value 2 means the BRIEF where we take a random point pair and compare their brightnesses,\nso we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3\nrandom points (of course, those point coordinates are random, but they are generated from the\npre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel\nrectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such\noutput will occupy 2 bits, and therefore it will need a special variant of Hamming distance,\ndenoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each\nbin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).\n@param scoreType The default HARRIS_SCORE means that Harris algorithm is used to rank features\n(the score is written to KeyPoint::score and is used to retain best nfeatures features);\nFAST_SCORE is alternative value of the parameter that produces slightly less stable keypoints,\nbut it is a little faster to compute.\n@param patchSize size of the patch used by the oriented BRIEF descriptor. Of course, on smaller\npyramid layers the perceived image area covered by a feature will be larger.\n@param fastThreshold']
docstring: @brief The ORB constructor

@param nfeatures The maximum number of features to retain.
@param scaleFactor Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical
pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor
will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor
will mean that to cover certain scale range you will need more pyramid levels and so the speed
will suffer.
@param nlevels The number of pyramid levels. The smallest level will have linear size equal to
input_image_linear_size/pow(scaleFactor, nlevels).
@param edgeThreshold This is size of the border where the features are not detected. It should
roughly match the patchSize parameter.
@param firstLevel It should be 0 in the current implementation.
@param WTA_K The number of points that produce each element of the oriented BRIEF descriptor. The
default value 2 means the BRIEF where we take a random point pair and compare their brightnesses,
so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3
random points (of course, those point coordinates are random, but they are generated from the
pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel
rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such
output will occupy 2 bits, and therefore it will need a special variant of Hamming distance,
denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each
bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).
@param scoreType The default HARRIS_SCORE means that Harris algorithm is used to rank features
(the score is written to KeyPoint::score and is used to retain best nfeatures features);
FAST_SCORE is alternative value of the parameter that produces slightly less stable keypoints,
but it is a little faster to compute.
@param patchSize size of the patch used by the oriented BRIEF descriptor. Of course, on smaller
pyramid layers the perceived image area covered by a feature will be larger.
@param fastThreshold
ok: FUNC <Ptr_ORB cv.ORB.create [ARG int nfeatures=500, ARG float scaleFactor=1.2f, ARG int nlevels=8, ARG int edgeThreshold=31, ARG int firstLevel=0, ARG int WTA_K=2, ARG int scoreType=ORB::HARRIS_SCORE, ARG int patchSize=31, ARG int fastThreshold=20]>

--- Incoming ---
[   u'cv.ORB.setMaxFeatures',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'maxFeatures', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setMaxFeatures [ARG int maxFeatures=]>

--- Incoming ---
[u'cv.ORB.getMaxFeatures', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getMaxFeatures []>

--- Incoming ---
[   u'cv.ORB.setScaleFactor',
    u'void',
    ['/V', '/PV'],
    [[u'double', u'scaleFactor', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setScaleFactor [ARG double scaleFactor=]>

--- Incoming ---
[u'cv.ORB.getScaleFactor', u'double', ['/C', '/V', '/PV'], [], u'double', '']
ok: FUNC <double cv.ORB.getScaleFactor []>

--- Incoming ---
[   u'cv.ORB.setNLevels',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'nlevels', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setNLevels [ARG int nlevels=]>

--- Incoming ---
[u'cv.ORB.getNLevels', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getNLevels []>

--- Incoming ---
[   u'cv.ORB.setEdgeThreshold',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'edgeThreshold', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setEdgeThreshold [ARG int edgeThreshold=]>

--- Incoming ---
[u'cv.ORB.getEdgeThreshold', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getEdgeThreshold []>

--- Incoming ---
[   u'cv.ORB.setFirstLevel',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'firstLevel', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setFirstLevel [ARG int firstLevel=]>

--- Incoming ---
[u'cv.ORB.getFirstLevel', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getFirstLevel []>

--- Incoming ---
[   u'cv.ORB.setWTA_K',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'wta_k', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setWTA_K [ARG int wta_k=]>

--- Incoming ---
[u'cv.ORB.getWTA_K', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getWTA_K []>

--- Incoming ---
[   u'cv.ORB.setScoreType',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'scoreType', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setScoreType [ARG int scoreType=]>

--- Incoming ---
[u'cv.ORB.getScoreType', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getScoreType []>

--- Incoming ---
[   u'cv.ORB.setPatchSize',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'patchSize', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setPatchSize [ARG int patchSize=]>

--- Incoming ---
[u'cv.ORB.getPatchSize', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getPatchSize []>

--- Incoming ---
[   u'cv.ORB.setFastThreshold',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'fastThreshold', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.ORB.setFastThreshold [ARG int fastThreshold=]>

--- Incoming ---
[u'cv.ORB.getFastThreshold', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.ORB.getFastThreshold []>

--- Incoming ---
[u'cv.ORB.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.ORB.getDefaultName []>

--- Incoming ---
[   u'class cv.MSER',
    u': cv::Feature2D',
    [],
    [],
    None,
    u"@brief Maximally stable extremal region extractor\n\nThe class encapsulates all the parameters of the %MSER extraction algorithm (see [wiki\narticle](http://en.wikipedia.org/wiki/Maximally_stable_extremal_regions)).\n\n- there are two different implementation of %MSER: one for grey image, one for color image\n\n- the grey image algorithm is taken from: @cite nister2008linear ;  the paper claims to be faster\nthan union-find method; it actually get 1.5~2m/s on my centrino L7200 1.2GHz laptop.\n\n- the color image algorithm is taken from: @cite forssen2007maximally ; it should be much slower\nthan grey image method ( 3~4 times ); the chi_table.h file is taken directly from paper's source\ncode which is distributed under GPL.\n\n- (Python) A complete example showing the use of the %MSER detector can be found at samples/python/mser.py"]
docstring: @brief Maximally stable extremal region extractor

The class encapsulates all the parameters of the %MSER extraction algorithm (see [wiki
article](http://en.wikipedia.org/wiki/Maximally_stable_extremal_regions)).

- there are two different implementation of %MSER: one for grey image, one for color image

- the grey image algorithm is taken from: @cite nister2008linear ;  the paper claims to be faster
than union-find method; it actually get 1.5~2m/s on my centrino L7200 1.2GHz laptop.

- the color image algorithm is taken from: @cite forssen2007maximally ; it should be much slower
than grey image method ( 3~4 times ); the chi_table.h file is taken directly from paper's source
code which is distributed under GPL.

- (Python) A complete example showing the use of the %MSER detector can be found at samples/python/mser.py
ok: class CLASS cv::.MSER : Feature2D, name: MSER, base: Feature2D

--- Incoming ---
[   u'cv.MSER.create',
    u'Ptr_MSER',
    ['/S'],
    [   [u'int', u'_delta', u'5', []],
        [u'int', u'_min_area', u'60', []],
        [u'int', u'_max_area', u'14400', []],
        [u'double', u'_max_variation', u'0.25', []],
        [u'double', u'_min_diversity', u'.2', []],
        [u'int', u'_max_evolution', u'200', []],
        [u'double', u'_area_threshold', u'1.01', []],
        [u'double', u'_min_margin', u'0.003', []],
        [u'int', u'_edge_blur_size', u'5', []]],
    u'Ptr<MSER>',
    u'@brief Full consturctor for %MSER detector\n\n@param _delta it compares \\f$(size_{i}-size_{i-delta})/size_{i-delta}\\f$\n@param _min_area prune the area which smaller than minArea\n@param _max_area prune the area which bigger than maxArea\n@param _max_variation prune the area have simliar size to its children\n@param _min_diversity for color image, trace back to cut off mser with diversity less than min_diversity\n@param _max_evolution  for color image, the evolution steps\n@param _area_threshold for color image, the area threshold to cause re-initialize\n@param _min_margin for color image, ignore too small margin\n@param _edge_blur_size for color image, the aperture size for edge blur']
docstring: @brief Full consturctor for %MSER detector

@param _delta it compares \f$(size_{i}-size_{i-delta})/size_{i-delta}\f$
@param _min_area prune the area which smaller than minArea
@param _max_area prune the area which bigger than maxArea
@param _max_variation prune the area have simliar size to its children
@param _min_diversity for color image, trace back to cut off mser with diversity less than min_diversity
@param _max_evolution  for color image, the evolution steps
@param _area_threshold for color image, the area threshold to cause re-initialize
@param _min_margin for color image, ignore too small margin
@param _edge_blur_size for color image, the aperture size for edge blur
ok: FUNC <Ptr_MSER cv.MSER.create [ARG int _delta=5, ARG int _min_area=60, ARG int _max_area=14400, ARG double _max_variation=0.25, ARG double _min_diversity=.2, ARG int _max_evolution=200, ARG double _area_threshold=1.01, ARG double _min_margin=0.003, ARG int _edge_blur_size=5]>

--- Incoming ---
[   u'cv.MSER.detectRegions',
    u'void',
    ['/V', '/PV'],
    [   ['Mat', u'image', '', []],
        [u'vector_vector_Point', u'msers', u'', ['/O', '/Ref']],
        [u'vector_Rect', u'bboxes', u'', ['/O', '/Ref']]],
    u'void',
    u'@brief Detect %MSER regions\n\n@param image input image (8UC1, 8UC3 or 8UC4, must be greater or equal than 3x3)\n@param msers resulting list of point sets\n@param bboxes resulting bounding boxes']
docstring: @brief Detect %MSER regions

@param image input image (8UC1, 8UC3 or 8UC4, must be greater or equal than 3x3)
@param msers resulting list of point sets
@param bboxes resulting bounding boxes
ok: FUNC <void cv.MSER.detectRegions [ARG Mat image=, ARG vector_vector_Point msers=, ARG vector_Rect bboxes=]>

--- Incoming ---
[   u'cv.MSER.setDelta',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'delta', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.MSER.setDelta [ARG int delta=]>

--- Incoming ---
[u'cv.MSER.getDelta', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.MSER.getDelta []>

--- Incoming ---
[   u'cv.MSER.setMinArea',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'minArea', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.MSER.setMinArea [ARG int minArea=]>

--- Incoming ---
[u'cv.MSER.getMinArea', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.MSER.getMinArea []>

--- Incoming ---
[   u'cv.MSER.setMaxArea',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'maxArea', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.MSER.setMaxArea [ARG int maxArea=]>

--- Incoming ---
[u'cv.MSER.getMaxArea', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.MSER.getMaxArea []>

--- Incoming ---
[   u'cv.MSER.setPass2Only',
    u'void',
    ['/V', '/PV'],
    [[u'bool', u'f', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.MSER.setPass2Only [ARG bool f=]>

--- Incoming ---
[u'cv.MSER.getPass2Only', u'bool', ['/C', '/V', '/PV'], [], u'bool', '']
ok: FUNC <bool cv.MSER.getPass2Only []>

--- Incoming ---
[u'cv.MSER.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.MSER.getDefaultName []>

--- Incoming ---
[   u'class cv.FastFeatureDetector',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Wrapping class for feature detection using the FAST method. :']
docstring: @brief Wrapping class for feature detection using the FAST method. :
ok: class CLASS cv::.FastFeatureDetector : Feature2D, name: FastFeatureDetector, base: Feature2D

--- Incoming ---
[u'const cv.FastFeatureDetector.TYPE_5_8', u'0', [], [], None, '']
ok: CONST TYPE_5_8=0

--- Incoming ---
[u'const cv.FastFeatureDetector.TYPE_7_12', u'1', [], [], None, '']
ok: CONST TYPE_7_12=1

--- Incoming ---
[u'const cv.FastFeatureDetector.TYPE_9_16', u'2', [], [], None, '']
ok: CONST TYPE_9_16=2

--- Incoming ---
[u'const cv.FastFeatureDetector.THRESHOLD', u'10000', [], [], None, '']
ok: CONST THRESHOLD=10000

--- Incoming ---
[   u'const cv.FastFeatureDetector.NONMAX_SUPPRESSION',
    u'10001',
    [],
    [],
    None,
    '']
ok: CONST NONMAX_SUPPRESSION=10001

--- Incoming ---
[u'const cv.FastFeatureDetector.FAST_N', u'10002', [], [], None, '']
ok: CONST FAST_N=10002

--- Incoming ---
[   u'cv.FastFeatureDetector.create',
    u'Ptr_FastFeatureDetector',
    ['/S'],
    [   [u'int', u'threshold', u'10', []],
        [u'bool', u'nonmaxSuppression', u'true', []],
        [u'int', u'type', u'FastFeatureDetector::TYPE_9_16', []]],
    u'Ptr<FastFeatureDetector>',
    '']
ok: FUNC <Ptr_FastFeatureDetector cv.FastFeatureDetector.create [ARG int threshold=10, ARG bool nonmaxSuppression=true, ARG int type=FastFeatureDetector::TYPE_9_16]>

--- Incoming ---
[   u'cv.FastFeatureDetector.setThreshold',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'threshold', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.FastFeatureDetector.setThreshold [ARG int threshold=]>

--- Incoming ---
[   u'cv.FastFeatureDetector.getThreshold',
    u'int',
    ['/C', '/V', '/PV'],
    [],
    u'int',
    '']
ok: FUNC <int cv.FastFeatureDetector.getThreshold []>

--- Incoming ---
[   u'cv.FastFeatureDetector.setNonmaxSuppression',
    u'void',
    ['/V', '/PV'],
    [[u'bool', u'f', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.FastFeatureDetector.setNonmaxSuppression [ARG bool f=]>

--- Incoming ---
[   u'cv.FastFeatureDetector.getNonmaxSuppression',
    u'bool',
    ['/C', '/V', '/PV'],
    [],
    u'bool',
    '']
ok: FUNC <bool cv.FastFeatureDetector.getNonmaxSuppression []>

--- Incoming ---
[   u'cv.FastFeatureDetector.setType',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'type', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.FastFeatureDetector.setType [ARG int type=]>

--- Incoming ---
[   u'cv.FastFeatureDetector.getType',
    u'int',
    ['/C', '/V', '/PV'],
    [],
    u'int',
    '']
ok: FUNC <int cv.FastFeatureDetector.getType []>

--- Incoming ---
[   u'cv.FastFeatureDetector.getDefaultName',
    u'String',
    ['/C', '/V'],
    [],
    u'String',
    '']
ok: FUNC <String cv.FastFeatureDetector.getDefaultName []>

--- Incoming ---
[   u'class cv.AgastFeatureDetector',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Wrapping class for feature detection using the AGAST method. :']
docstring: @brief Wrapping class for feature detection using the AGAST method. :
ok: class CLASS cv::.AgastFeatureDetector : Feature2D, name: AgastFeatureDetector, base: Feature2D

--- Incoming ---
[u'const cv.AgastFeatureDetector.AGAST_5_8', u'0', [], [], None, '']
ok: CONST AGAST_5_8=0

--- Incoming ---
[u'const cv.AgastFeatureDetector.AGAST_7_12d', u'1', [], [], None, '']
ok: CONST AGAST_7_12d=1

--- Incoming ---
[u'const cv.AgastFeatureDetector.AGAST_7_12s', u'2', [], [], None, '']
ok: CONST AGAST_7_12s=2

--- Incoming ---
[u'const cv.AgastFeatureDetector.OAST_9_16', u'3', [], [], None, '']
ok: CONST OAST_9_16=3

--- Incoming ---
[u'const cv.AgastFeatureDetector.THRESHOLD', u'10000', [], [], None, '']
ok: CONST THRESHOLD=10000

--- Incoming ---
[   u'const cv.AgastFeatureDetector.NONMAX_SUPPRESSION',
    u'10001',
    [],
    [],
    None,
    '']
ok: CONST NONMAX_SUPPRESSION=10001

--- Incoming ---
[   u'cv.AgastFeatureDetector.create',
    u'Ptr_AgastFeatureDetector',
    ['/S'],
    [   [u'int', u'threshold', u'10', []],
        [u'bool', u'nonmaxSuppression', u'true', []],
        [u'int', u'type', u'AgastFeatureDetector::OAST_9_16', []]],
    u'Ptr<AgastFeatureDetector>',
    '']
ok: FUNC <Ptr_AgastFeatureDetector cv.AgastFeatureDetector.create [ARG int threshold=10, ARG bool nonmaxSuppression=true, ARG int type=AgastFeatureDetector::OAST_9_16]>

--- Incoming ---
[   u'cv.AgastFeatureDetector.setThreshold',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'threshold', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AgastFeatureDetector.setThreshold [ARG int threshold=]>

--- Incoming ---
[   u'cv.AgastFeatureDetector.getThreshold',
    u'int',
    ['/C', '/V', '/PV'],
    [],
    u'int',
    '']
ok: FUNC <int cv.AgastFeatureDetector.getThreshold []>

--- Incoming ---
[   u'cv.AgastFeatureDetector.setNonmaxSuppression',
    u'void',
    ['/V', '/PV'],
    [[u'bool', u'f', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AgastFeatureDetector.setNonmaxSuppression [ARG bool f=]>

--- Incoming ---
[   u'cv.AgastFeatureDetector.getNonmaxSuppression',
    u'bool',
    ['/C', '/V', '/PV'],
    [],
    u'bool',
    '']
ok: FUNC <bool cv.AgastFeatureDetector.getNonmaxSuppression []>

--- Incoming ---
[   u'cv.AgastFeatureDetector.setType',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'type', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AgastFeatureDetector.setType [ARG int type=]>

--- Incoming ---
[   u'cv.AgastFeatureDetector.getType',
    u'int',
    ['/C', '/V', '/PV'],
    [],
    u'int',
    '']
ok: FUNC <int cv.AgastFeatureDetector.getType []>

--- Incoming ---
[   u'cv.AgastFeatureDetector.getDefaultName',
    u'String',
    ['/C', '/V'],
    [],
    u'String',
    '']
ok: FUNC <String cv.AgastFeatureDetector.getDefaultName []>

--- Incoming ---
[   u'class cv.GFTTDetector',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Wrapping class for feature detection using the goodFeaturesToTrack function. :']
docstring: @brief Wrapping class for feature detection using the goodFeaturesToTrack function. :
ok: class CLASS cv::.GFTTDetector : Feature2D, name: GFTTDetector, base: Feature2D

--- Incoming ---
[   u'cv.GFTTDetector.create',
    u'Ptr_GFTTDetector',
    ['/S'],
    [   [u'int', u'maxCorners', u'1000', []],
        [u'double', u'qualityLevel', u'0.01', []],
        [u'double', u'minDistance', u'1', []],
        [u'int', u'blockSize', u'3', []],
        [u'bool', u'useHarrisDetector', u'false', []],
        [u'double', u'k', u'0.04', []]],
    u'Ptr<GFTTDetector>',
    '']
ok: FUNC <Ptr_GFTTDetector cv.GFTTDetector.create [ARG int maxCorners=1000, ARG double qualityLevel=0.01, ARG double minDistance=1, ARG int blockSize=3, ARG bool useHarrisDetector=false, ARG double k=0.04]>

--- Incoming ---
[   u'cv.GFTTDetector.create',
    u'Ptr_GFTTDetector',
    ['/S'],
    [   [u'int', u'maxCorners', u'', []],
        [u'double', u'qualityLevel', u'', []],
        [u'double', u'minDistance', u'', []],
        [u'int', u'blockSize', u'', []],
        [u'int', u'gradiantSize', u'', []],
        [u'bool', u'useHarrisDetector', u'false', []],
        [u'double', u'k', u'0.04', []]],
    u'Ptr<GFTTDetector>',
    '']
ok: FUNC <Ptr_GFTTDetector cv.GFTTDetector.create [ARG int maxCorners=, ARG double qualityLevel=, ARG double minDistance=, ARG int blockSize=, ARG int gradiantSize=, ARG bool useHarrisDetector=false, ARG double k=0.04]>

--- Incoming ---
[   u'cv.GFTTDetector.setMaxFeatures',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'maxFeatures', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.GFTTDetector.setMaxFeatures [ARG int maxFeatures=]>

--- Incoming ---
[   u'cv.GFTTDetector.getMaxFeatures',
    u'int',
    ['/C', '/V', '/PV'],
    [],
    u'int',
    '']
ok: FUNC <int cv.GFTTDetector.getMaxFeatures []>

--- Incoming ---
[   u'cv.GFTTDetector.setQualityLevel',
    u'void',
    ['/V', '/PV'],
    [[u'double', u'qlevel', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.GFTTDetector.setQualityLevel [ARG double qlevel=]>

--- Incoming ---
[   u'cv.GFTTDetector.getQualityLevel',
    u'double',
    ['/C', '/V', '/PV'],
    [],
    u'double',
    '']
ok: FUNC <double cv.GFTTDetector.getQualityLevel []>

--- Incoming ---
[   u'cv.GFTTDetector.setMinDistance',
    u'void',
    ['/V', '/PV'],
    [[u'double', u'minDistance', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.GFTTDetector.setMinDistance [ARG double minDistance=]>

--- Incoming ---
[   u'cv.GFTTDetector.getMinDistance',
    u'double',
    ['/C', '/V', '/PV'],
    [],
    u'double',
    '']
ok: FUNC <double cv.GFTTDetector.getMinDistance []>

--- Incoming ---
[   u'cv.GFTTDetector.setBlockSize',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'blockSize', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.GFTTDetector.setBlockSize [ARG int blockSize=]>

--- Incoming ---
[u'cv.GFTTDetector.getBlockSize', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.GFTTDetector.getBlockSize []>

--- Incoming ---
[   u'cv.GFTTDetector.setHarrisDetector',
    u'void',
    ['/V', '/PV'],
    [[u'bool', u'val', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.GFTTDetector.setHarrisDetector [ARG bool val=]>

--- Incoming ---
[   u'cv.GFTTDetector.getHarrisDetector',
    u'bool',
    ['/C', '/V', '/PV'],
    [],
    u'bool',
    '']
ok: FUNC <bool cv.GFTTDetector.getHarrisDetector []>

--- Incoming ---
[   u'cv.GFTTDetector.setK',
    u'void',
    ['/V', '/PV'],
    [[u'double', u'k', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.GFTTDetector.setK [ARG double k=]>

--- Incoming ---
[u'cv.GFTTDetector.getK', u'double', ['/C', '/V', '/PV'], [], u'double', '']
ok: FUNC <double cv.GFTTDetector.getK []>

--- Incoming ---
[u'cv.GFTTDetector.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.GFTTDetector.getDefaultName []>

--- Incoming ---
[   u'class cv.SimpleBlobDetector',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Class for extracting blobs from an image. :\n\nThe class implements a simple algorithm for extracting blobs from an image:\n\n1.  Convert the source image to binary images by applying thresholding with several thresholds from\nminThreshold (inclusive) to maxThreshold (exclusive) with distance thresholdStep between\nneighboring thresholds.\n2.  Extract connected components from every binary image by findContours and calculate their\ncenters.\n3.  Group centers from several binary images by their coordinates. Close centers form one group that\ncorresponds to one blob, which is controlled by the minDistBetweenBlobs parameter.\n4.  From the groups, estimate final centers of blobs and their radiuses and return as locations and\nsizes of keypoints.\n\nThis class performs several filtrations of returned blobs. You should set filterBy\\* to true/false\nto turn on/off corresponding filtration. Available filtrations:\n\n-   **By color**. This filter compares the intensity of a binary image at the center of a blob to\nblobColor. If they differ, the blob is filtered out. Use blobColor = 0 to extract dark blobs\nand blobColor = 255 to extract light blobs.\n-   **By area**. Extracted blobs have an area between minArea (inclusive) and maxArea (exclusive).\n-   **By circularity**. Extracted blobs have circularity\n(\\f$\\frac{4*\\pi*Area}{perimeter * perimeter}\\f$) between minCircularity (inclusive) and\nmaxCircularity (exclusive).\n-   **By ratio of the minimum inertia to maximum inertia**. Extracted blobs have this ratio\nbetween minInertiaRatio (inclusive) and maxInertiaRatio (exclusive).\n-   **By convexity**. Extracted blobs have convexity (area / area of blob convex hull) between\nminConvexity (inclusive) and maxConvexity (exclusive).\n\nDefault values of parameters are tuned to extract dark circular blobs.']
docstring: @brief Class for extracting blobs from an image. :

The class implements a simple algorithm for extracting blobs from an image:

1.  Convert the source image to binary images by applying thresholding with several thresholds from
minThreshold (inclusive) to maxThreshold (exclusive) with distance thresholdStep between
neighboring thresholds.
2.  Extract connected components from every binary image by findContours and calculate their
centers.
3.  Group centers from several binary images by their coordinates. Close centers form one group that
corresponds to one blob, which is controlled by the minDistBetweenBlobs parameter.
4.  From the groups, estimate final centers of blobs and their radiuses and return as locations and
sizes of keypoints.

This class performs several filtrations of returned blobs. You should set filterBy\* to true/false
to turn on/off corresponding filtration. Available filtrations:

-   **By color**. This filter compares the intensity of a binary image at the center of a blob to
blobColor. If they differ, the blob is filtered out. Use blobColor = 0 to extract dark blobs
and blobColor = 255 to extract light blobs.
-   **By area**. Extracted blobs have an area between minArea (inclusive) and maxArea (exclusive).
-   **By circularity**. Extracted blobs have circularity
(\f$\frac{4*\pi*Area}{perimeter * perimeter}\f$) between minCircularity (inclusive) and
maxCircularity (exclusive).
-   **By ratio of the minimum inertia to maximum inertia**. Extracted blobs have this ratio
between minInertiaRatio (inclusive) and maxInertiaRatio (exclusive).
-   **By convexity**. Extracted blobs have convexity (area / area of blob convex hull) between
minConvexity (inclusive) and maxConvexity (exclusive).

Default values of parameters are tuned to extract dark circular blobs.
ignored: CLASS cv::.SimpleBlobDetector : Feature2D

--- Incoming ---
[   u'struct cv.SimpleBlobDetector.Params',
    '',
    ['/Simple'],
    [   [u'float', u'thresholdStep', '', ['/RW']],
        [u'float', u'minThreshold', '', ['/RW']],
        [u'float', u'maxThreshold', '', ['/RW']],
        [u'size_t', u'minRepeatability', '', ['/RW']],
        [u'float', u'minDistBetweenBlobs', '', ['/RW']],
        [u'bool', u'filterByColor', '', ['/RW']],
        [u'uchar', u'blobColor', '', ['/RW']],
        [u'bool', u'filterByArea', '', ['/RW']],
        [u'float', u'minArea', '', ['/RW']],
        [u'float', u'maxArea', '', ['/RW']],
        [u'bool', u'filterByCircularity', '', ['/RW']],
        [u'float', u'minCircularity', '', ['/RW']],
        [u'float', u'maxCircularity', '', ['/RW']],
        [u'bool', u'filterByInertia', '', ['/RW']],
        [u'float', u'minInertiaRatio', '', ['/RW']],
        [u'float', u'maxInertiaRatio', '', ['/RW']],
        [u'bool', u'filterByConvexity', '', ['/RW']],
        [u'float', u'minConvexity', '', ['/RW']],
        [u'float', u'maxConvexity', '', ['/RW']]],
    None,
    '']
ok: class CLASS cv::SimpleBlobDetector.Params : , name: Params, base: 

--- Incoming ---
[u'cv.SimpleBlobDetector.Params.Params', '', [], [], None, '']
ok: FUNC < cv.SimpleBlobDetector.Params.Params []>

--- Incoming ---
[   u'cv.SimpleBlobDetector.create',
    u'Ptr_SimpleBlobDetector',
    ['/S'],
    [   [   u'SimpleBlobDetector_Params',
            u'parameters',
            u'SimpleBlobDetector::Params()',
            ['/C', '/Ref']]],
    u'Ptr<SimpleBlobDetector>',
    '']
ignored: FUNC <Ptr_SimpleBlobDetector cv.SimpleBlobDetector.create [ARG SimpleBlobDetector_Params parameters=SimpleBlobDetector::Params()]>

--- Incoming ---
[   u'cv.SimpleBlobDetector.getDefaultName',
    u'String',
    ['/C', '/V'],
    [],
    u'String',
    '']
ignored: FUNC <String cv.SimpleBlobDetector.getDefaultName []>

--- Incoming ---
[   u'class cv.KAZE',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Class implementing the KAZE keypoint detector and descriptor extractor, described in @cite ABD12 .\n\n@note AKAZE descriptor can only be used with KAZE or AKAZE keypoints .. [ABD12] KAZE Features. Pablo\nF. Alcantarilla, Adrien Bartoli and Andrew J. Davison. In European Conference on Computer Vision\n(ECCV), Fiorenze, Italy, October 2012.']
docstring: @brief Class implementing the KAZE keypoint detector and descriptor extractor, described in @cite ABD12 .

@note AKAZE descriptor can only be used with KAZE or AKAZE keypoints .. [ABD12] KAZE Features. Pablo
F. Alcantarilla, Adrien Bartoli and Andrew J. Davison. In European Conference on Computer Vision
(ECCV), Fiorenze, Italy, October 2012.
ok: class CLASS cv::.KAZE : Feature2D, name: KAZE, base: Feature2D

--- Incoming ---
[u'const cv.KAZE.DIFF_PM_G1', u'0', [], [], None, '']
ok: CONST DIFF_PM_G1=0

--- Incoming ---
[u'const cv.KAZE.DIFF_PM_G2', u'1', [], [], None, '']
ok: CONST DIFF_PM_G2=1

--- Incoming ---
[u'const cv.KAZE.DIFF_WEICKERT', u'2', [], [], None, '']
ok: CONST DIFF_WEICKERT=2

--- Incoming ---
[u'const cv.KAZE.DIFF_CHARBONNIER', u'3', [], [], None, '']
ok: CONST DIFF_CHARBONNIER=3

--- Incoming ---
[   u'cv.KAZE.create',
    u'Ptr_KAZE',
    ['/S'],
    [   [u'bool', u'extended', u'false', []],
        [u'bool', u'upright', u'false', []],
        [u'float', u'threshold', u'0.001f', []],
        [u'int', u'nOctaves', u'4', []],
        [u'int', u'nOctaveLayers', u'4', []],
        [u'int', u'diffusivity', u'KAZE::DIFF_PM_G2', []]],
    u'Ptr<KAZE>',
    u'@brief The KAZE constructor\n\n@param extended Set to enable extraction of extended (128-byte) descriptor.\n@param upright Set to enable use of upright descriptors (non rotation-invariant).\n@param threshold Detector response threshold to accept point\n@param nOctaves Maximum octave evolution of the image\n@param nOctaveLayers Default number of sublevels per scale level\n@param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\nDIFF_CHARBONNIER']
docstring: @brief The KAZE constructor

@param extended Set to enable extraction of extended (128-byte) descriptor.
@param upright Set to enable use of upright descriptors (non rotation-invariant).
@param threshold Detector response threshold to accept point
@param nOctaves Maximum octave evolution of the image
@param nOctaveLayers Default number of sublevels per scale level
@param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or
DIFF_CHARBONNIER
ok: FUNC <Ptr_KAZE cv.KAZE.create [ARG bool extended=false, ARG bool upright=false, ARG float threshold=0.001f, ARG int nOctaves=4, ARG int nOctaveLayers=4, ARG int diffusivity=KAZE::DIFF_PM_G2]>

--- Incoming ---
[   u'cv.KAZE.setExtended',
    u'void',
    ['/V', '/PV'],
    [[u'bool', u'extended', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.KAZE.setExtended [ARG bool extended=]>

--- Incoming ---
[u'cv.KAZE.getExtended', u'bool', ['/C', '/V', '/PV'], [], u'bool', '']
ok: FUNC <bool cv.KAZE.getExtended []>

--- Incoming ---
[   u'cv.KAZE.setUpright',
    u'void',
    ['/V', '/PV'],
    [[u'bool', u'upright', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.KAZE.setUpright [ARG bool upright=]>

--- Incoming ---
[u'cv.KAZE.getUpright', u'bool', ['/C', '/V', '/PV'], [], u'bool', '']
ok: FUNC <bool cv.KAZE.getUpright []>

--- Incoming ---
[   u'cv.KAZE.setThreshold',
    u'void',
    ['/V', '/PV'],
    [[u'double', u'threshold', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.KAZE.setThreshold [ARG double threshold=]>

--- Incoming ---
[u'cv.KAZE.getThreshold', u'double', ['/C', '/V', '/PV'], [], u'double', '']
ok: FUNC <double cv.KAZE.getThreshold []>

--- Incoming ---
[   u'cv.KAZE.setNOctaves',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'octaves', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.KAZE.setNOctaves [ARG int octaves=]>

--- Incoming ---
[u'cv.KAZE.getNOctaves', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.KAZE.getNOctaves []>

--- Incoming ---
[   u'cv.KAZE.setNOctaveLayers',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'octaveLayers', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.KAZE.setNOctaveLayers [ARG int octaveLayers=]>

--- Incoming ---
[u'cv.KAZE.getNOctaveLayers', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.KAZE.getNOctaveLayers []>

--- Incoming ---
[   u'cv.KAZE.setDiffusivity',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'diff', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.KAZE.setDiffusivity [ARG int diff=]>

--- Incoming ---
[u'cv.KAZE.getDiffusivity', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.KAZE.getDiffusivity []>

--- Incoming ---
[u'cv.KAZE.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.KAZE.getDefaultName []>

--- Incoming ---
[   u'class cv.AKAZE',
    u': cv::Feature2D',
    [],
    [],
    None,
    u'@brief Class implementing the AKAZE keypoint detector and descriptor extractor, described in @cite ANB13.\n\n@details AKAZE descriptors can only be used with KAZE or AKAZE keypoints. This class is thread-safe.\n\n@note When you need descriptors use Feature2D::detectAndCompute, which\nprovides better performance. When using Feature2D::detect followed by\nFeature2D::compute scale space pyramid is computed twice.\n\n@note AKAZE implements T-API. When image is passed as UMat some parts of the algorithm\nwill use OpenCL.\n\n@note [ANB13] Fast Explicit Diffusion for Accelerated Features in Nonlinear\nScale Spaces. Pablo F. Alcantarilla, Jes\xfas Nuevo and Adrien Bartoli. In\nBritish Machine Vision Conference (BMVC), Bristol, UK, September 2013.']
docstring: @brief Class implementing the AKAZE keypoint detector and descriptor extractor, described in @cite ANB13.

@details AKAZE descriptors can only be used with KAZE or AKAZE keypoints. This class is thread-safe.

@note When you need descriptors use Feature2D::detectAndCompute, which
provides better performance. When using Feature2D::detect followed by
Feature2D::compute scale space pyramid is computed twice.

@note AKAZE implements T-API. When image is passed as UMat some parts of the algorithm
will use OpenCL.

@note [ANB13] Fast Explicit Diffusion for Accelerated Features in Nonlinear
Scale Spaces. Pablo F. Alcantarilla, Jesús Nuevo and Adrien Bartoli. In
British Machine Vision Conference (BMVC), Bristol, UK, September 2013.
ok: class CLASS cv::.AKAZE : Feature2D, name: AKAZE, base: Feature2D

--- Incoming ---
[u'const cv.AKAZE.DESCRIPTOR_KAZE_UPRIGHT', u'2', [], [], None, '']
ok: CONST DESCRIPTOR_KAZE_UPRIGHT=2

--- Incoming ---
[u'const cv.AKAZE.DESCRIPTOR_KAZE', u'3', [], [], None, '']
ok: CONST DESCRIPTOR_KAZE=3

--- Incoming ---
[u'const cv.AKAZE.DESCRIPTOR_MLDB_UPRIGHT', u'4', [], [], None, '']
ok: CONST DESCRIPTOR_MLDB_UPRIGHT=4

--- Incoming ---
[u'const cv.AKAZE.DESCRIPTOR_MLDB', u'5', [], [], None, '']
ok: CONST DESCRIPTOR_MLDB=5

--- Incoming ---
[   u'cv.AKAZE.create',
    u'Ptr_AKAZE',
    ['/S'],
    [   [u'int', u'descriptor_type', u'AKAZE::DESCRIPTOR_MLDB', []],
        [u'int', u'descriptor_size', u'0', []],
        [u'int', u'descriptor_channels', u'3', []],
        [u'float', u'threshold', u'0.001f', []],
        [u'int', u'nOctaves', u'4', []],
        [u'int', u'nOctaveLayers', u'4', []],
        [u'int', u'diffusivity', u'KAZE::DIFF_PM_G2', []]],
    u'Ptr<AKAZE>',
    u'@brief The AKAZE constructor\n\n@param descriptor_type Type of the extracted descriptor: DESCRIPTOR_KAZE,\nDESCRIPTOR_KAZE_UPRIGHT, DESCRIPTOR_MLDB or DESCRIPTOR_MLDB_UPRIGHT.\n@param descriptor_size Size of the descriptor in bits. 0 -\\> Full size\n@param descriptor_channels Number of channels in the descriptor (1, 2, 3)\n@param threshold Detector response threshold to accept point\n@param nOctaves Maximum octave evolution of the image\n@param nOctaveLayers Default number of sublevels per scale level\n@param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\nDIFF_CHARBONNIER']
docstring: @brief The AKAZE constructor

@param descriptor_type Type of the extracted descriptor: DESCRIPTOR_KAZE,
DESCRIPTOR_KAZE_UPRIGHT, DESCRIPTOR_MLDB or DESCRIPTOR_MLDB_UPRIGHT.
@param descriptor_size Size of the descriptor in bits. 0 -\> Full size
@param descriptor_channels Number of channels in the descriptor (1, 2, 3)
@param threshold Detector response threshold to accept point
@param nOctaves Maximum octave evolution of the image
@param nOctaveLayers Default number of sublevels per scale level
@param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or
DIFF_CHARBONNIER
ok: FUNC <Ptr_AKAZE cv.AKAZE.create [ARG int descriptor_type=AKAZE::DESCRIPTOR_MLDB, ARG int descriptor_size=0, ARG int descriptor_channels=3, ARG float threshold=0.001f, ARG int nOctaves=4, ARG int nOctaveLayers=4, ARG int diffusivity=KAZE::DIFF_PM_G2]>

--- Incoming ---
[   u'cv.AKAZE.setDescriptorType',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'dtype', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setDescriptorType [ARG int dtype=]>

--- Incoming ---
[u'cv.AKAZE.getDescriptorType', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.AKAZE.getDescriptorType []>

--- Incoming ---
[   u'cv.AKAZE.setDescriptorSize',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'dsize', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setDescriptorSize [ARG int dsize=]>

--- Incoming ---
[u'cv.AKAZE.getDescriptorSize', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.AKAZE.getDescriptorSize []>

--- Incoming ---
[   u'cv.AKAZE.setDescriptorChannels',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'dch', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setDescriptorChannels [ARG int dch=]>

--- Incoming ---
[   u'cv.AKAZE.getDescriptorChannels',
    u'int',
    ['/C', '/V', '/PV'],
    [],
    u'int',
    '']
ok: FUNC <int cv.AKAZE.getDescriptorChannels []>

--- Incoming ---
[   u'cv.AKAZE.setThreshold',
    u'void',
    ['/V', '/PV'],
    [[u'double', u'threshold', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setThreshold [ARG double threshold=]>

--- Incoming ---
[u'cv.AKAZE.getThreshold', u'double', ['/C', '/V', '/PV'], [], u'double', '']
ok: FUNC <double cv.AKAZE.getThreshold []>

--- Incoming ---
[   u'cv.AKAZE.setNOctaves',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'octaves', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setNOctaves [ARG int octaves=]>

--- Incoming ---
[u'cv.AKAZE.getNOctaves', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.AKAZE.getNOctaves []>

--- Incoming ---
[   u'cv.AKAZE.setNOctaveLayers',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'octaveLayers', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setNOctaveLayers [ARG int octaveLayers=]>

--- Incoming ---
[u'cv.AKAZE.getNOctaveLayers', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.AKAZE.getNOctaveLayers []>

--- Incoming ---
[   u'cv.AKAZE.setDiffusivity',
    u'void',
    ['/V', '/PV'],
    [[u'int', u'diff', u'', []]],
    u'void',
    '']
ok: FUNC <void cv.AKAZE.setDiffusivity [ARG int diff=]>

--- Incoming ---
[u'cv.AKAZE.getDiffusivity', u'int', ['/C', '/V', '/PV'], [], u'int', '']
ok: FUNC <int cv.AKAZE.getDiffusivity []>

--- Incoming ---
[u'cv.AKAZE.getDefaultName', u'String', ['/C', '/V'], [], u'String', '']
ok: FUNC <String cv.AKAZE.getDefaultName []>

--- Incoming ---
[   u'class cv.DescriptorMatcher',
    ': cv::Algorithm',
    [],
    [],
    None,
    u'@brief Abstract base class for matching keypoint descriptors.\n\nIt has two groups of match methods: for matching descriptors of an image with another image or with\nan image set.']
docstring: @brief Abstract base class for matching keypoint descriptors.

It has two groups of match methods: for matching descriptors of an image with another image or with
an image set.
ok: class CLASS cv::.DescriptorMatcher : Algorithm, name: DescriptorMatcher, base: Algorithm

--- Incoming ---
[u'const cv.DescriptorMatcher.FLANNBASED', u'1', [], [], None, '']
ok: CONST FLANNBASED=1

--- Incoming ---
[u'const cv.DescriptorMatcher.BRUTEFORCE', u'2', [], [], None, '']
ok: CONST BRUTEFORCE=2

--- Incoming ---
[u'const cv.DescriptorMatcher.BRUTEFORCE_L1', u'3', [], [], None, '']
ok: CONST BRUTEFORCE_L1=3

--- Incoming ---
[u'const cv.DescriptorMatcher.BRUTEFORCE_HAMMING', u'4', [], [], None, '']
ok: CONST BRUTEFORCE_HAMMING=4

--- Incoming ---
[u'const cv.DescriptorMatcher.BRUTEFORCE_HAMMINGLUT', u'5', [], [], None, '']
ok: CONST BRUTEFORCE_HAMMINGLUT=5

--- Incoming ---
[u'const cv.DescriptorMatcher.BRUTEFORCE_SL2', u'6', [], [], None, '']
ok: CONST BRUTEFORCE_SL2=6

--- Incoming ---
[   u'cv.DescriptorMatcher.add',
    u'void',
    ['/V'],
    [['vector_Mat', u'descriptors', '', []]],
    u'void',
    u'@brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\ncollection.\n\nIf the collection is not empty, the new descriptors are added to existing train descriptors.\n\n@param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\ntrain image.']
docstring: @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor
collection.

If the collection is not empty, the new descriptors are added to existing train descriptors.

@param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same
train image.
ok: FUNC <void cv.DescriptorMatcher.add [ARG vector_Mat descriptors=]>

--- Incoming ---
[   u'cv.DescriptorMatcher.getTrainDescriptors',
    u'vector_Mat',
    ['/C'],
    [],
    u'std::vector<Mat>',
    u'@brief Returns a constant link to the train descriptor collection trainDescCollection .']
docstring: @brief Returns a constant link to the train descriptor collection trainDescCollection .
ok: FUNC <vector_Mat cv.DescriptorMatcher.getTrainDescriptors []>

--- Incoming ---
[   u'cv.DescriptorMatcher.clear',
    u'void',
    ['/V'],
    [],
    u'void',
    u'@brief Clears the train descriptor collections.']
docstring: @brief Clears the train descriptor collections.
ok: FUNC <void cv.DescriptorMatcher.clear []>

--- Incoming ---
[   u'cv.DescriptorMatcher.empty',
    u'bool',
    ['/C', '/V'],
    [],
    u'bool',
    u'@brief Returns true if there are no train descriptors in the both collections.']
docstring: @brief Returns true if there are no train descriptors in the both collections.
ok: FUNC <bool cv.DescriptorMatcher.empty []>

--- Incoming ---
[   u'cv.DescriptorMatcher.isMaskSupported',
    u'bool',
    ['/C', '/V', '/PV'],
    [],
    u'bool',
    u'@brief Returns true if the descriptor matcher supports masking permissible matches.']
docstring: @brief Returns true if the descriptor matcher supports masking permissible matches.
ok: FUNC <bool cv.DescriptorMatcher.isMaskSupported []>

--- Incoming ---
[   u'cv.DescriptorMatcher.train',
    u'void',
    ['/V'],
    [],
    u'void',
    u'@brief Trains a descriptor matcher\n\nTrains a descriptor matcher (for example, the flann index). In all methods to match, the method\ntrain() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\nhave an empty implementation of this method. Other matchers really train their inner structures (for\nexample, FlannBasedMatcher trains flann::Index ).']
docstring: @brief Trains a descriptor matcher

Trains a descriptor matcher (for example, the flann index). In all methods to match, the method
train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)
have an empty implementation of this method. Other matchers really train their inner structures (for
example, FlannBasedMatcher trains flann::Index ).
ok: FUNC <void cv.DescriptorMatcher.train []>

--- Incoming ---
[   u'cv.DescriptorMatcher.match',
    u'void',
    ['/C'],
    [   ['Mat', u'queryDescriptors', '', []],
        ['Mat', u'trainDescriptors', '', []],
        [u'vector_DMatch', u'matches', u'', ['/O', '/Ref']],
        ['Mat', u'mask', u'Mat()', []]],
    u'void',
    u'@brief Finds the best match for each descriptor from a query set.\n\n@param queryDescriptors Query set of descriptors.\n@param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\ncollection stored in the class object.\n@param matches Matches. If a query descriptor is masked out in mask , no match is added for this\ndescriptor. So, matches size may be smaller than the query descriptors count.\n@param mask Mask specifying permissible matches between an input query and train matrices of\ndescriptors.\n\nIn the first variant of this method, the train descriptors are passed as an input argument. In the\nsecond variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\nused. Optional mask (or masks) can be passed to specify which query and training descriptors can be\nmatched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\nmask.at\\<uchar\\>(i,j) is non-zero.']
docstring: @brief Finds the best match for each descriptor from a query set.

@param queryDescriptors Query set of descriptors.
@param trainDescriptors Train set of descriptors. This set is not added to the train descriptors
collection stored in the class object.
@param matches Matches. If a query descriptor is masked out in mask , no match is added for this
descriptor. So, matches size may be smaller than the query descriptors count.
@param mask Mask specifying permissible matches between an input query and train matrices of
descriptors.

In the first variant of this method, the train descriptors are passed as an input argument. In the
second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is
used. Optional mask (or masks) can be passed to specify which query and training descriptors can be
matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if
mask.at\<uchar\>(i,j) is non-zero.
ok: FUNC <void cv.DescriptorMatcher.match [ARG Mat queryDescriptors=, ARG Mat trainDescriptors=, ARG vector_DMatch matches=, ARG Mat mask=Mat()]>

--- Incoming ---
[   u'cv.DescriptorMatcher.knnMatch',
    u'void',
    ['/C'],
    [   ['Mat', u'queryDescriptors', '', []],
        ['Mat', u'trainDescriptors', '', []],
        [u'vector_vector_DMatch', u'matches', u'', ['/O', '/Ref']],
        [u'int', u'k', u'', []],
        ['Mat', u'mask', u'Mat()', []],
        [u'bool', u'compactResult', u'false', []]],
    u'void',
    u'@brief Finds the k best matches for each descriptor from a query set.\n\n@param queryDescriptors Query set of descriptors.\n@param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\ncollection stored in the class object.\n@param mask Mask specifying permissible matches between an input query and train matrices of\ndescriptors.\n@param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n@param k Count of best matches found per each query descriptor or less if a query descriptor has\nless than k possible matches in total.\n@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\nfalse, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\nthe matches vector does not contain matches for fully masked-out query descriptors.\n\nThese extended variants of DescriptorMatcher::match methods find several best matches for each query\ndescriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\nfor the details about query and train descriptors.']
docstring: @brief Finds the k best matches for each descriptor from a query set.

@param queryDescriptors Query set of descriptors.
@param trainDescriptors Train set of descriptors. This set is not added to the train descriptors
collection stored in the class object.
@param mask Mask specifying permissible matches between an input query and train matrices of
descriptors.
@param matches Matches. Each matches[i] is k or less matches for the same query descriptor.
@param k Count of best matches found per each query descriptor or less if a query descriptor has
less than k possible matches in total.
@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is
false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,
the matches vector does not contain matches for fully masked-out query descriptors.

These extended variants of DescriptorMatcher::match methods find several best matches for each query
descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match
for the details about query and train descriptors.
ok: FUNC <void cv.DescriptorMatcher.knnMatch [ARG Mat queryDescriptors=, ARG Mat trainDescriptors=, ARG vector_vector_DMatch matches=, ARG int k=, ARG Mat mask=Mat(), ARG bool compactResult=false]>

--- Incoming ---
[   u'cv.DescriptorMatcher.radiusMatch',
    u'void',
    ['/C'],
    [   ['Mat', u'queryDescriptors', '', []],
        ['Mat', u'trainDescriptors', '', []],
        [u'vector_vector_DMatch', u'matches', u'', ['/O', '/Ref']],
        [u'float', u'maxDistance', u'', []],
        ['Mat', u'mask', u'Mat()', []],
        [u'bool', u'compactResult', u'false', []]],
    u'void',
    u'@brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n\n@param queryDescriptors Query set of descriptors.\n@param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\ncollection stored in the class object.\n@param matches Found matches.\n@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\nfalse, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\nthe matches vector does not contain matches for fully masked-out query descriptors.\n@param maxDistance Threshold for the distance between matched descriptors. Distance means here\nmetric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\nin Pixels)!\n@param mask Mask specifying permissible matches between an input query and train matrices of\ndescriptors.\n\nFor each query descriptor, the methods find such training descriptors that the distance between the\nquery descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\nreturned in the distance increasing order.']
docstring: @brief For each query descriptor, finds the training descriptors not farther than the specified distance.

@param queryDescriptors Query set of descriptors.
@param trainDescriptors Train set of descriptors. This set is not added to the train descriptors
collection stored in the class object.
@param matches Found matches.
@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is
false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,
the matches vector does not contain matches for fully masked-out query descriptors.
@param maxDistance Threshold for the distance between matched descriptors. Distance means here
metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured
in Pixels)!
@param mask Mask specifying permissible matches between an input query and train matrices of
descriptors.

For each query descriptor, the methods find such training descriptors that the distance between the
query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are
returned in the distance increasing order.
ok: FUNC <void cv.DescriptorMatcher.radiusMatch [ARG Mat queryDescriptors=, ARG Mat trainDescriptors=, ARG vector_vector_DMatch matches=, ARG float maxDistance=, ARG Mat mask=Mat(), ARG bool compactResult=false]>

--- Incoming ---
[   u'cv.DescriptorMatcher.match',
    u'void',
    [],
    [   ['Mat', u'queryDescriptors', '', []],
        [u'vector_DMatch', u'matches', u'', ['/O', '/Ref']],
        ['vector_Mat', u'masks', u'vector_Mat()', []]],
    u'void',
    u'@overload\n@param queryDescriptors Query set of descriptors.\n@param matches Matches. If a query descriptor is masked out in mask , no match is added for this\ndescriptor. So, matches size may be smaller than the query descriptors count.\n@param masks Set of masks. Each masks[i] specifies permissible matches between the input query\ndescriptors and stored train descriptors from the i-th image trainDescCollection[i].']
docstring: @overload
@param queryDescriptors Query set of descriptors.
@param matches Matches. If a query descriptor is masked out in mask , no match is added for this
descriptor. So, matches size may be smaller than the query descriptors count.
@param masks Set of masks. Each masks[i] specifies permissible matches between the input query
descriptors and stored train descriptors from the i-th image trainDescCollection[i].
ok: FUNC <void cv.DescriptorMatcher.match [ARG Mat queryDescriptors=, ARG vector_DMatch matches=, ARG vector_Mat masks=vector_Mat()]>

--- Incoming ---
[   u'cv.DescriptorMatcher.knnMatch',
    u'void',
    [],
    [   ['Mat', u'queryDescriptors', '', []],
        [u'vector_vector_DMatch', u'matches', u'', ['/O', '/Ref']],
        [u'int', u'k', u'', []],
        ['vector_Mat', u'masks', u'vector_Mat()', []],
        [u'bool', u'compactResult', u'false', []]],
    u'void',
    u'@overload\n@param queryDescriptors Query set of descriptors.\n@param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n@param k Count of best matches found per each query descriptor or less if a query descriptor has\nless than k possible matches in total.\n@param masks Set of masks. Each masks[i] specifies permissible matches between the input query\ndescriptors and stored train descriptors from the i-th image trainDescCollection[i].\n@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\nfalse, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\nthe matches vector does not contain matches for fully masked-out query descriptors.']
docstring: @overload
@param queryDescriptors Query set of descriptors.
@param matches Matches. Each matches[i] is k or less matches for the same query descriptor.
@param k Count of best matches found per each query descriptor or less if a query descriptor has
less than k possible matches in total.
@param masks Set of masks. Each masks[i] specifies permissible matches between the input query
descriptors and stored train descriptors from the i-th image trainDescCollection[i].
@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is
false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,
the matches vector does not contain matches for fully masked-out query descriptors.
ok: FUNC <void cv.DescriptorMatcher.knnMatch [ARG Mat queryDescriptors=, ARG vector_vector_DMatch matches=, ARG int k=, ARG vector_Mat masks=vector_Mat(), ARG bool compactResult=false]>

--- Incoming ---
[   u'cv.DescriptorMatcher.radiusMatch',
    u'void',
    [],
    [   ['Mat', u'queryDescriptors', '', []],
        [u'vector_vector_DMatch', u'matches', u'', ['/O', '/Ref']],
        [u'float', u'maxDistance', u'', []],
        ['vector_Mat', u'masks', u'vector_Mat()', []],
        [u'bool', u'compactResult', u'false', []]],
    u'void',
    u'@overload\n@param queryDescriptors Query set of descriptors.\n@param matches Found matches.\n@param maxDistance Threshold for the distance between matched descriptors. Distance means here\nmetric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\nin Pixels)!\n@param masks Set of masks. Each masks[i] specifies permissible matches between the input query\ndescriptors and stored train descriptors from the i-th image trainDescCollection[i].\n@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\nfalse, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\nthe matches vector does not contain matches for fully masked-out query descriptors.']
docstring: @overload
@param queryDescriptors Query set of descriptors.
@param matches Found matches.
@param maxDistance Threshold for the distance between matched descriptors. Distance means here
metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured
in Pixels)!
@param masks Set of masks. Each masks[i] specifies permissible matches between the input query
descriptors and stored train descriptors from the i-th image trainDescCollection[i].
@param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is
false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,
the matches vector does not contain matches for fully masked-out query descriptors.
ok: FUNC <void cv.DescriptorMatcher.radiusMatch [ARG Mat queryDescriptors=, ARG vector_vector_DMatch matches=, ARG float maxDistance=, ARG vector_Mat masks=vector_Mat(), ARG bool compactResult=false]>

--- Incoming ---
[   u'cv.DescriptorMatcher.write',
    u'void',
    ['/C'],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.DescriptorMatcher.write [ARG String fileName=]>

--- Incoming ---
[   u'cv.DescriptorMatcher.read',
    u'void',
    [],
    [[u'String', u'fileName', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.DescriptorMatcher.read [ARG String fileName=]>

--- Incoming ---
[   u'cv.DescriptorMatcher.read',
    u'void',
    ['/V'],
    [[u'FileNode', 'arg1', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.DescriptorMatcher.read [ARG FileNode arg1=]>

--- Incoming ---
[   u'cv.DescriptorMatcher.clone',
    u'Ptr_DescriptorMatcher',
    ['/C', '/V', '/PV'],
    [[u'bool', u'emptyTrainData', u'false', []]],
    u'Ptr<DescriptorMatcher>',
    u'@brief Clones the matcher.\n\n@param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\nthat is, copies both parameters and train data. If emptyTrainData is true, the method creates an\nobject copy with the current parameters but with empty train data.']
docstring: @brief Clones the matcher.

@param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,
that is, copies both parameters and train data. If emptyTrainData is true, the method creates an
object copy with the current parameters but with empty train data.
ok: FUNC <Ptr_DescriptorMatcher cv.DescriptorMatcher.clone [ARG bool emptyTrainData=false]>

--- Incoming ---
[   u'cv.DescriptorMatcher.create',
    u'Ptr_DescriptorMatcher',
    ['/S'],
    [[u'String', u'descriptorMatcherType', u'', ['/C', '/Ref']]],
    u'Ptr<DescriptorMatcher>',
    u'@brief Creates a descriptor matcher of a given type with the default parameters (using default\nconstructor).\n\n@param descriptorMatcherType Descriptor matcher type. Now the following matcher types are\nsupported:\n-   `BruteForce` (it uses L2 )\n-   `BruteForce-L1`\n-   `BruteForce-Hamming`\n-   `BruteForce-Hamming(2)`\n-   `FlannBased`']
docstring: @brief Creates a descriptor matcher of a given type with the default parameters (using default
constructor).

@param descriptorMatcherType Descriptor matcher type. Now the following matcher types are
supported:
-   `BruteForce` (it uses L2 )
-   `BruteForce-L1`
-   `BruteForce-Hamming`
-   `BruteForce-Hamming(2)`
-   `FlannBased`
ok: FUNC <Ptr_DescriptorMatcher cv.DescriptorMatcher.create [ARG String descriptorMatcherType=]>

--- Incoming ---
[   u'cv.DescriptorMatcher.create',
    u'Ptr_DescriptorMatcher',
    ['/S'],
    [[u'int', u'matcherType', u'', []]],
    u'Ptr<DescriptorMatcher>',
    '']
ok: FUNC <Ptr_DescriptorMatcher cv.DescriptorMatcher.create [ARG int matcherType=]>

--- Incoming ---
[   u'cv.DescriptorMatcher.write',
    u'void',
    ['/C'],
    [   [u'Ptr_FileStorage', u'fs', u'', ['/C', '/Ref']],
        [u'String', u'name', u'String()', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.DescriptorMatcher.write [ARG Ptr_FileStorage fs=, ARG String name=String()]>

--- Incoming ---
[   u'class cv.BFMatcher',
    u': cv::DescriptorMatcher',
    [],
    [],
    None,
    u'@brief Brute-force descriptor matcher.\n\nFor each descriptor in the first set, this matcher finds the closest descriptor in the second set\nby trying each one. This descriptor matcher supports masking permissible matches of descriptor\nsets.']
docstring: @brief Brute-force descriptor matcher.

For each descriptor in the first set, this matcher finds the closest descriptor in the second set
by trying each one. This descriptor matcher supports masking permissible matches of descriptor
sets.
ok: class CLASS cv::.BFMatcher : DescriptorMatcher, name: BFMatcher, base: DescriptorMatcher

--- Incoming ---
[   u'cv.BFMatcher.BFMatcher',
    '',
    [],
    [   [u'int', u'normType', u'NORM_L2', []],
        [u'bool', u'crossCheck', u'false', []]],
    None,
    u'@brief Brute-force matcher constructor (obsolete). Please use BFMatcher.create()\n*\n*']
docstring: @brief Brute-force matcher constructor (obsolete). Please use BFMatcher.create()
*
*
ok: FUNC < cv.BFMatcher.BFMatcher [ARG int normType=NORM_L2, ARG bool crossCheck=false]>

--- Incoming ---
[   u'cv.BFMatcher.create',
    u'Ptr_BFMatcher',
    ['/S'],
    [   [u'int', u'normType', u'NORM_L2', []],
        [u'bool', u'crossCheck', u'false', []]],
    u'Ptr<BFMatcher>',
    u"@brief Brute-force matcher create method.\n@param normType One of NORM_L1, NORM_L2, NORM_HAMMING, NORM_HAMMING2. L1 and L2 norms are\npreferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\nBRIEF, NORM_HAMMING2 should be used with ORB when WTA_K==3 or 4 (see ORB::ORB constructor\ndescription).\n@param crossCheck If it is false, this is will be default BFMatcher behaviour when it finds the k\nnearest neighbors for each query descriptor. If crossCheck==true, then the knnMatch() method with\nk=1 will only return pairs (i,j) such that for i-th query descriptor the j-th descriptor in the\nmatcher's collection is the nearest and vice versa, i.e. the BFMatcher will only return consistent\npairs. Such technique usually produces best results with minimal number of outliers when there are\nenough matches. This is alternative to the ratio test, used by D. Lowe in SIFT paper."]
docstring: @brief Brute-force matcher create method.
@param normType One of NORM_L1, NORM_L2, NORM_HAMMING, NORM_HAMMING2. L1 and L2 norms are
preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and
BRIEF, NORM_HAMMING2 should be used with ORB when WTA_K==3 or 4 (see ORB::ORB constructor
description).
@param crossCheck If it is false, this is will be default BFMatcher behaviour when it finds the k
nearest neighbors for each query descriptor. If crossCheck==true, then the knnMatch() method with
k=1 will only return pairs (i,j) such that for i-th query descriptor the j-th descriptor in the
matcher's collection is the nearest and vice versa, i.e. the BFMatcher will only return consistent
pairs. Such technique usually produces best results with minimal number of outliers when there are
enough matches. This is alternative to the ratio test, used by D. Lowe in SIFT paper.
ok: FUNC <Ptr_BFMatcher cv.BFMatcher.create [ARG int normType=NORM_L2, ARG bool crossCheck=false]>

--- Incoming ---
[   u'class cv.FlannBasedMatcher',
    u': cv::DescriptorMatcher',
    [],
    [],
    None,
    u'@brief Flann-based descriptor matcher.\n\nThis matcher trains cv::flann::Index on a train descriptor collection and calls its nearest search\nmethods to find the best matches. So, this matcher may be faster when matching a large train\ncollection than the brute force matcher. FlannBasedMatcher does not support masking permissible\nmatches of descriptor sets because flann::Index does not support this. :']
docstring: @brief Flann-based descriptor matcher.

This matcher trains cv::flann::Index on a train descriptor collection and calls its nearest search
methods to find the best matches. So, this matcher may be faster when matching a large train
collection than the brute force matcher. FlannBasedMatcher does not support masking permissible
matches of descriptor sets because flann::Index does not support this. :
ok: class CLASS cv::.FlannBasedMatcher : DescriptorMatcher, name: FlannBasedMatcher, base: DescriptorMatcher

--- Incoming ---
[   u'cv.FlannBasedMatcher.FlannBasedMatcher',
    '',
    [],
    [   [   u'Ptr_flann_IndexParams',
            u'indexParams',
            u'makePtr<flann::KDTreeIndexParams>()',
            ['/C', '/Ref']],
        [   u'Ptr_flann_SearchParams',
            u'searchParams',
            u'makePtr<flann::SearchParams>()',
            ['/C', '/Ref']]],
    None,
    '']
ok: FUNC < cv.FlannBasedMatcher.FlannBasedMatcher [ARG Ptr_flann_IndexParams indexParams=makePtr<flann::KDTreeIndexParams>(), ARG Ptr_flann_SearchParams searchParams=makePtr<flann::SearchParams>()]>

--- Incoming ---
[   u'cv.FlannBasedMatcher.create',
    u'Ptr_FlannBasedMatcher',
    ['/S'],
    [],
    u'Ptr<FlannBasedMatcher>',
    '']
ok: FUNC <Ptr_FlannBasedMatcher cv.FlannBasedMatcher.create []>

--- Incoming ---
[u'const cv.DrawMatchesFlags.DEFAULT', u'0', [], [], None, '']
class not found: CONST DEFAULT=0

--- Incoming ---
[u'const cv.DrawMatchesFlags.DRAW_OVER_OUTIMG', u'1', [], [], None, '']
class not found: CONST DRAW_OVER_OUTIMG=1

--- Incoming ---
[u'const cv.DrawMatchesFlags.NOT_DRAW_SINGLE_POINTS', u'2', [], [], None, '']
class not found: CONST NOT_DRAW_SINGLE_POINTS=2

--- Incoming ---
[u'const cv.DrawMatchesFlags.DRAW_RICH_KEYPOINTS', u'4', [], [], None, '']
class not found: CONST DRAW_RICH_KEYPOINTS=4

--- Incoming ---
[   u'cv.drawKeypoints',
    u'void',
    [],
    [   ['Mat', u'image', '', []],
        [u'vector_KeyPoint', u'keypoints', u'', ['/C', '/Ref']],
        ['Mat', u'outImage', '', ['/IO']],
        [u'Scalar', u'color', u'Scalar::all(-1)', ['/C', '/Ref']],
        [u'int', u'flags', u'DrawMatchesFlags::DEFAULT', []]],
    u'void',
    u'@brief Draws keypoints.\n\n@param image Source image.\n@param keypoints Keypoints from the source image.\n@param outImage Output image. Its content depends on the flags value defining what is drawn in the\noutput image. See possible flags bit values below.\n@param color Color of keypoints.\n@param flags Flags setting drawing features. Possible flags bit values are defined by\nDrawMatchesFlags. See details above in drawMatches .\n\n@note\nFor Python API, flags are modified as cv2.DRAW_MATCHES_FLAGS_DEFAULT,\ncv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG,\ncv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS']
docstring: @brief Draws keypoints.

@param image Source image.
@param keypoints Keypoints from the source image.
@param outImage Output image. Its content depends on the flags value defining what is drawn in the
output image. See possible flags bit values below.
@param color Color of keypoints.
@param flags Flags setting drawing features. Possible flags bit values are defined by
DrawMatchesFlags. See details above in drawMatches .

@note
For Python API, flags are modified as cv2.DRAW_MATCHES_FLAGS_DEFAULT,
cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG,
cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS
ok: FUNC <void cv..drawKeypoints [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat outImage=, ARG Scalar color=Scalar::all(-1), ARG int flags=DrawMatchesFlags::DEFAULT]>

--- Incoming ---
[   u'cv.drawMatches',
    u'void',
    [],
    [   ['Mat', u'img1', '', []],
        [u'vector_KeyPoint', u'keypoints1', u'', ['/C', '/Ref']],
        ['Mat', u'img2', '', []],
        [u'vector_KeyPoint', u'keypoints2', u'', ['/C', '/Ref']],
        [u'vector_DMatch', u'matches1to2', u'', ['/C', '/Ref']],
        ['Mat', u'outImg', '', ['/IO']],
        [u'Scalar', u'matchColor', u'Scalar::all(-1)', ['/C', '/Ref']],
        [u'Scalar', u'singlePointColor', u'Scalar::all(-1)', ['/C', '/Ref']],
        [   u'vector_char',
            u'matchesMask',
            u'std::vector<char>()',
            ['/C', '/Ref']],
        [u'int', u'flags', u'DrawMatchesFlags::DEFAULT', []]],
    u'void',
    u'@brief Draws the found matches of keypoints from two images.\n\n@param img1 First source image.\n@param keypoints1 Keypoints from the first source image.\n@param img2 Second source image.\n@param keypoints2 Keypoints from the second source image.\n@param matches1to2 Matches from the first image to the second one, which means that keypoints1[i]\nhas a corresponding point in keypoints2[matches[i]] .\n@param outImg Output image. Its content depends on the flags value defining what is drawn in the\noutput image. See possible flags bit values below.\n@param matchColor Color of matches (lines and connected keypoints). If matchColor==Scalar::all(-1)\n, the color is generated randomly.\n@param singlePointColor Color of single keypoints (circles), which means that keypoints do not\nhave the matches. If singlePointColor==Scalar::all(-1) , the color is generated randomly.\n@param matchesMask Mask determining which matches are drawn. If the mask is empty, all matches are\ndrawn.\n@param flags Flags setting drawing features. Possible flags bit values are defined by\nDrawMatchesFlags.\n\nThis function draws matches of keypoints from two images in the output image. Match is a line\nconnecting two keypoints (circles). See cv::DrawMatchesFlags.']
docstring: @brief Draws the found matches of keypoints from two images.

@param img1 First source image.
@param keypoints1 Keypoints from the first source image.
@param img2 Second source image.
@param keypoints2 Keypoints from the second source image.
@param matches1to2 Matches from the first image to the second one, which means that keypoints1[i]
has a corresponding point in keypoints2[matches[i]] .
@param outImg Output image. Its content depends on the flags value defining what is drawn in the
output image. See possible flags bit values below.
@param matchColor Color of matches (lines and connected keypoints). If matchColor==Scalar::all(-1)
, the color is generated randomly.
@param singlePointColor Color of single keypoints (circles), which means that keypoints do not
have the matches. If singlePointColor==Scalar::all(-1) , the color is generated randomly.
@param matchesMask Mask determining which matches are drawn. If the mask is empty, all matches are
drawn.
@param flags Flags setting drawing features. Possible flags bit values are defined by
DrawMatchesFlags.

This function draws matches of keypoints from two images in the output image. Match is a line
connecting two keypoints (circles). See cv::DrawMatchesFlags.
ok: FUNC <void cv..drawMatches [ARG Mat img1=, ARG vector_KeyPoint keypoints1=, ARG Mat img2=, ARG vector_KeyPoint keypoints2=, ARG vector_DMatch matches1to2=, ARG Mat outImg=, ARG Scalar matchColor=Scalar::all(-1), ARG Scalar singlePointColor=Scalar::all(-1), ARG vector_char matchesMask=std::vector<char>(), ARG int flags=DrawMatchesFlags::DEFAULT]>

--- Incoming ---
[   u'cv.drawMatches',
    u'void',
    [u'=drawMatchesKnn'],
    [   ['Mat', u'img1', '', []],
        [u'vector_KeyPoint', u'keypoints1', u'', ['/C', '/Ref']],
        ['Mat', u'img2', '', []],
        [u'vector_KeyPoint', u'keypoints2', u'', ['/C', '/Ref']],
        [u'vector_vector_DMatch', u'matches1to2', u'', ['/C', '/Ref']],
        ['Mat', u'outImg', '', ['/IO']],
        [u'Scalar', u'matchColor', u'Scalar::all(-1)', ['/C', '/Ref']],
        [u'Scalar', u'singlePointColor', u'Scalar::all(-1)', ['/C', '/Ref']],
        [   u'vector_vector_char',
            u'matchesMask',
            u'std::vector<std::vector<char> >()',
            ['/C', '/Ref']],
        [u'int', u'flags', u'DrawMatchesFlags::DEFAULT', []]],
    u'void',
    u'@overload']
docstring: @overload
ok: FUNC <void cv..drawMatches [ARG Mat img1=, ARG vector_KeyPoint keypoints1=, ARG Mat img2=, ARG vector_KeyPoint keypoints2=, ARG vector_vector_DMatch matches1to2=, ARG Mat outImg=, ARG Scalar matchColor=Scalar::all(-1), ARG Scalar singlePointColor=Scalar::all(-1), ARG vector_vector_char matchesMask=std::vector<std::vector<char> >(), ARG int flags=DrawMatchesFlags::DEFAULT]>

--- Incoming ---
[   u'class cv.BOWTrainer',
    '',
    [],
    [],
    None,
    u'@brief Abstract base class for training the *bag of visual words* vocabulary from a set of descriptors.\n\nFor details, see, for example, *Visual Categorization with Bags of Keypoints* by Gabriella Csurka,\nChristopher R. Dance, Lixin Fan, Jutta Willamowski, Cedric Bray, 2004. :']
docstring: @brief Abstract base class for training the *bag of visual words* vocabulary from a set of descriptors.

For details, see, for example, *Visual Categorization with Bags of Keypoints* by Gabriella Csurka,
Christopher R. Dance, Lixin Fan, Jutta Willamowski, Cedric Bray, 2004. :
ok: class CLASS cv::.BOWTrainer : , name: BOWTrainer, base: 

--- Incoming ---
[   u'cv.BOWTrainer.add',
    u'void',
    [],
    [[u'Mat', u'descriptors', u'', ['/C', '/Ref']]],
    u'void',
    u'@brief Adds descriptors to a training set.\n\n@param descriptors Descriptors to add to a training set. Each row of the descriptors matrix is a\ndescriptor.\n\nThe training set is clustered using clustermethod to construct the vocabulary.']
docstring: @brief Adds descriptors to a training set.

@param descriptors Descriptors to add to a training set. Each row of the descriptors matrix is a
descriptor.

The training set is clustered using clustermethod to construct the vocabulary.
ok: FUNC <void cv.BOWTrainer.add [ARG Mat descriptors=]>

--- Incoming ---
[   u'cv.BOWTrainer.getDescriptors',
    u'vector_Mat',
    ['/C'],
    [],
    u'std::vector<Mat>',
    u'@brief Returns a training set of descriptors.']
docstring: @brief Returns a training set of descriptors.
ok: FUNC <vector_Mat cv.BOWTrainer.getDescriptors []>

--- Incoming ---
[   u'cv.BOWTrainer.descriptorsCount',
    u'int',
    ['/C'],
    [],
    u'int',
    u'@brief Returns the count of all descriptors stored in the training set.']
docstring: @brief Returns the count of all descriptors stored in the training set.
ok: FUNC <int cv.BOWTrainer.descriptorsCount []>

--- Incoming ---
[u'cv.BOWTrainer.clear', u'void', ['/V'], [], u'void', '']
ok: FUNC <void cv.BOWTrainer.clear []>

--- Incoming ---
[   u'cv.BOWTrainer.cluster',
    u'Mat',
    ['/C', '/V', '/PV'],
    [],
    u'Mat',
    u'@overload']
docstring: @overload
ok: FUNC <Mat cv.BOWTrainer.cluster []>

--- Incoming ---
[   u'cv.BOWTrainer.cluster',
    u'Mat',
    ['/C', '/V', '/PV'],
    [[u'Mat', u'descriptors', u'', ['/C', '/Ref']]],
    u'Mat',
    u'@brief Clusters train descriptors.\n\n@param descriptors Descriptors to cluster. Each row of the descriptors matrix is a descriptor.\nDescriptors are not added to the inner train descriptor set.\n\nThe vocabulary consists of cluster centers. So, this method returns the vocabulary. In the first\nvariant of the method, train descriptors stored in the object are clustered. In the second variant,\ninput descriptors are clustered.']
docstring: @brief Clusters train descriptors.

@param descriptors Descriptors to cluster. Each row of the descriptors matrix is a descriptor.
Descriptors are not added to the inner train descriptor set.

The vocabulary consists of cluster centers. So, this method returns the vocabulary. In the first
variant of the method, train descriptors stored in the object are clustered. In the second variant,
input descriptors are clustered.
ok: FUNC <Mat cv.BOWTrainer.cluster [ARG Mat descriptors=]>

--- Incoming ---
[   u'class cv.BOWKMeansTrainer',
    u': cv::BOWTrainer',
    [],
    [],
    None,
    u'@brief kmeans -based class to train visual vocabulary using the *bag of visual words* approach. :']
docstring: @brief kmeans -based class to train visual vocabulary using the *bag of visual words* approach. :
ok: class CLASS cv::.BOWKMeansTrainer : BOWTrainer, name: BOWKMeansTrainer, base: BOWTrainer

--- Incoming ---
[   u'cv.BOWKMeansTrainer.BOWKMeansTrainer',
    '',
    [],
    [   [u'int', u'clusterCount', u'', []],
        [u'TermCriteria', u'termcrit', u'TermCriteria()', ['/C', '/Ref']],
        [u'int', u'attempts', u'3', []],
        [u'int', u'flags', u'KMEANS_PP_CENTERS', []]],
    None,
    u'@brief The constructor.\n\n@see cv::kmeans']
docstring: @brief The constructor.

@see cv::kmeans
ok: FUNC < cv.BOWKMeansTrainer.BOWKMeansTrainer [ARG int clusterCount=, ARG TermCriteria termcrit=TermCriteria(), ARG int attempts=3, ARG int flags=KMEANS_PP_CENTERS]>

--- Incoming ---
[u'cv.BOWKMeansTrainer.cluster', u'Mat', ['/C', '/V'], [], u'Mat', '']
ok: FUNC <Mat cv.BOWKMeansTrainer.cluster []>

--- Incoming ---
[   u'cv.BOWKMeansTrainer.cluster',
    u'Mat',
    ['/C', '/V'],
    [[u'Mat', u'descriptors', u'', ['/C', '/Ref']]],
    u'Mat',
    '']
ok: FUNC <Mat cv.BOWKMeansTrainer.cluster [ARG Mat descriptors=]>

--- Incoming ---
[   u'class cv.BOWImgDescriptorExtractor',
    '',
    [],
    [],
    None,
    u'@brief Class to compute an image descriptor using the *bag of visual words*.\n\nSuch a computation consists of the following steps:\n\n1.  Compute descriptors for a given image and its keypoints set.\n2.  Find the nearest visual words from the vocabulary for each keypoint descriptor.\n3.  Compute the bag-of-words image descriptor as is a normalized histogram of vocabulary words\nencountered in the image. The i-th bin of the histogram is a frequency of i-th word of the\nvocabulary in the given image.']
docstring: @brief Class to compute an image descriptor using the *bag of visual words*.

Such a computation consists of the following steps:

1.  Compute descriptors for a given image and its keypoints set.
2.  Find the nearest visual words from the vocabulary for each keypoint descriptor.
3.  Compute the bag-of-words image descriptor as is a normalized histogram of vocabulary words
encountered in the image. The i-th bin of the histogram is a frequency of i-th word of the
vocabulary in the given image.
ok: class CLASS cv::.BOWImgDescriptorExtractor : , name: BOWImgDescriptorExtractor, base: 

--- Incoming ---
[   u'cv.BOWImgDescriptorExtractor.BOWImgDescriptorExtractor',
    '',
    [],
    [   [u'Ptr_DescriptorExtractor', u'dextractor', u'', ['/C', '/Ref']],
        [u'Ptr_DescriptorMatcher', u'dmatcher', u'', ['/C', '/Ref']]],
    None,
    u'@brief The constructor.\n\n@param dextractor Descriptor extractor that is used to compute descriptors for an input image and\nits keypoints.\n@param dmatcher Descriptor matcher that is used to find the nearest word of the trained vocabulary\nfor each keypoint descriptor of the image.']
docstring: @brief The constructor.

@param dextractor Descriptor extractor that is used to compute descriptors for an input image and
its keypoints.
@param dmatcher Descriptor matcher that is used to find the nearest word of the trained vocabulary
for each keypoint descriptor of the image.
ok: FUNC < cv.BOWImgDescriptorExtractor.BOWImgDescriptorExtractor [ARG Ptr_DescriptorExtractor dextractor=, ARG Ptr_DescriptorMatcher dmatcher=]>

--- Incoming ---
[   u'cv.BOWImgDescriptorExtractor.setVocabulary',
    u'void',
    [],
    [[u'Mat', u'vocabulary', u'', ['/C', '/Ref']]],
    u'void',
    u'@brief Sets a visual vocabulary.\n\n@param vocabulary Vocabulary (can be trained using the inheritor of BOWTrainer ). Each row of the\nvocabulary is a visual word (cluster center).']
docstring: @brief Sets a visual vocabulary.

@param vocabulary Vocabulary (can be trained using the inheritor of BOWTrainer ). Each row of the
vocabulary is a visual word (cluster center).
ok: FUNC <void cv.BOWImgDescriptorExtractor.setVocabulary [ARG Mat vocabulary=]>

--- Incoming ---
[   u'cv.BOWImgDescriptorExtractor.getVocabulary',
    u'Mat',
    ['/C'],
    [],
    u'Mat',
    u'@brief Returns the set vocabulary.']
docstring: @brief Returns the set vocabulary.
ok: FUNC <Mat cv.BOWImgDescriptorExtractor.getVocabulary []>

--- Incoming ---
[   u'cv.BOWImgDescriptorExtractor.compute2',
    u'void',
    [u'=compute'],
    [   [u'Mat', u'image', u'', ['/C', '/Ref']],
        [u'vector_KeyPoint', u'keypoints', u'', ['/Ref']],
        [u'Mat', u'imgDescriptor', u'', ['/O', '/Ref']]],
    u'void',
    u'@overload\n@param keypointDescriptors Computed descriptors to match with vocabulary.\n@param imgDescriptor Computed output image descriptor.\n@param pointIdxsOfClusters Indices of keypoints that belong to the cluster. This means that\npointIdxsOfClusters[i] are keypoint indices that belong to the i -th cluster (word of vocabulary)\nreturned if it is non-zero.']
docstring: @overload
@param keypointDescriptors Computed descriptors to match with vocabulary.
@param imgDescriptor Computed output image descriptor.
@param pointIdxsOfClusters Indices of keypoints that belong to the cluster. This means that
pointIdxsOfClusters[i] are keypoint indices that belong to the i -th cluster (word of vocabulary)
returned if it is non-zero.
ok: FUNC <void cv.BOWImgDescriptorExtractor.compute2 [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat imgDescriptor=]>

--- Incoming ---
[   u'cv.BOWImgDescriptorExtractor.descriptorSize',
    u'int',
    ['/C'],
    [],
    u'int',
    u'@brief Returns an image descriptor size if the vocabulary is set. Otherwise, it returns 0.']
docstring: @brief Returns an image descriptor size if the vocabulary is set. Otherwise, it returns 0.
ok: FUNC <int cv.BOWImgDescriptorExtractor.descriptorSize []>

--- Incoming ---
[   u'cv.BOWImgDescriptorExtractor.descriptorType',
    u'int',
    ['/C'],
    [],
    u'int',
    u'@brief Returns an image descriptor type.']
docstring: @brief Returns an image descriptor type.
ok: FUNC <int cv.BOWImgDescriptorExtractor.descriptorType []>


===== Generating... =====
CLASS cv::.BOWImgDescriptorExtractor : 
FUNC < cv.BOWImgDescriptorExtractor.BOWImgDescriptorExtractor [ARG Ptr_DescriptorExtractor dextractor=, ARG Ptr_DescriptorMatcher dmatcher=]>
SKIP:BOWImgDescriptorExtractor(Ptr_DescriptorExtractor dextractor, Ptr_DescriptorMatcher dmatcher)	 due to ARG typePtr_DescriptorExtractor/I
FUNC <Mat cv.BOWImgDescriptorExtractor.getVocabulary []>
java: Mat getVocabulary()
FUNC <int cv.BOWImgDescriptorExtractor.descriptorSize []>
java: int descriptorSize()
FUNC <int cv.BOWImgDescriptorExtractor.descriptorType []>
java: int descriptorType()
FUNC <void cv.BOWImgDescriptorExtractor.compute2 [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat imgDescriptor=]>
java: void compute(Mat image, MatOfKeyPoint keypoints, Mat imgDescriptor)
FUNC <void cv.BOWImgDescriptorExtractor.setVocabulary [ARG Mat vocabulary=]>
java: void setVocabulary(Mat vocabulary)
CLASS cv::.javaFeatureDetector : 
[CONST GRIDDETECTOR=1000, CONST PYRAMIDDETECTOR=2000, CONST DYNAMICDETECTOR=3000]
[CONST FAST=1, CONST STAR=2, CONST SIFT=3, CONST SURF=4, CONST ORB=5, CONST MSER=6, CONST GFTT=7, CONST HARRIS=8, CONST SIMPLEBLOB=9, CONST DENSE=10, CONST BRISK=11, CONST AKAZE=12, CONST GRID_FAST=GRIDDETECTOR + FAST, CONST GRID_STAR=GRIDDETECTOR + STAR, CONST GRID_SIFT=GRIDDETECTOR + SIFT, CONST GRID_SURF=GRIDDETECTOR + SURF, CONST GRID_ORB=GRIDDETECTOR + ORB, CONST GRID_MSER=GRIDDETECTOR + MSER, CONST GRID_GFTT=GRIDDETECTOR + GFTT, CONST GRID_HARRIS=GRIDDETECTOR + HARRIS, CONST GRID_SIMPLEBLOB=GRIDDETECTOR + SIMPLEBLOB, CONST GRID_DENSE=GRIDDETECTOR + DENSE, CONST GRID_BRISK=GRIDDETECTOR + BRISK, CONST GRID_AKAZE=GRIDDETECTOR + AKAZE, CONST PYRAMID_FAST=PYRAMIDDETECTOR + FAST, CONST PYRAMID_STAR=PYRAMIDDETECTOR + STAR, CONST PYRAMID_SIFT=PYRAMIDDETECTOR + SIFT, CONST PYRAMID_SURF=PYRAMIDDETECTOR + SURF, CONST PYRAMID_ORB=PYRAMIDDETECTOR + ORB, CONST PYRAMID_MSER=PYRAMIDDETECTOR + MSER, CONST PYRAMID_GFTT=PYRAMIDDETECTOR + GFTT, CONST PYRAMID_HARRIS=PYRAMIDDETECTOR + HARRIS, CONST PYRAMID_SIMPLEBLOB=PYRAMIDDETECTOR + SIMPLEBLOB, CONST PYRAMID_DENSE=PYRAMIDDETECTOR + DENSE, CONST PYRAMID_BRISK=PYRAMIDDETECTOR + BRISK, CONST PYRAMID_AKAZE=PYRAMIDDETECTOR + AKAZE, CONST DYNAMIC_FAST=DYNAMICDETECTOR + FAST, CONST DYNAMIC_STAR=DYNAMICDETECTOR + STAR, CONST DYNAMIC_SIFT=DYNAMICDETECTOR + SIFT, CONST DYNAMIC_SURF=DYNAMICDETECTOR + SURF, CONST DYNAMIC_ORB=DYNAMICDETECTOR + ORB, CONST DYNAMIC_MSER=DYNAMICDETECTOR + MSER, CONST DYNAMIC_GFTT=DYNAMICDETECTOR + GFTT, CONST DYNAMIC_HARRIS=DYNAMICDETECTOR + HARRIS, CONST DYNAMIC_SIMPLEBLOB=DYNAMICDETECTOR + SIMPLEBLOB, CONST DYNAMIC_DENSE=DYNAMICDETECTOR + DENSE, CONST DYNAMIC_BRISK=DYNAMICDETECTOR + BRISK, CONST DYNAMIC_AKAZE=DYNAMICDETECTOR + AKAZE]
FUNC <Ptr_javaFeatureDetector cv.javaFeatureDetector.create [ARG int detectorType=]>
java: FeatureDetector create(int detectorType)
FUNC <bool cv.javaFeatureDetector.empty []>
java: boolean empty()
FUNC <void cv.javaFeatureDetector.detect [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat mask=Mat()]>
java: void detect(Mat image, MatOfKeyPoint keypoints, Mat mask)
java: void detect(Mat image, MatOfKeyPoint keypoints)
FUNC <void cv.javaFeatureDetector.detect [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat masks=std::vector<Mat>()]>
java: void detect(List<Mat> images, List<MatOfKeyPoint> keypoints, List<Mat> masks)
java: void detect(List<Mat> images, List<MatOfKeyPoint> keypoints)
FUNC <void cv.javaFeatureDetector.read [ARG String fileName=]>
java: void read(String fileName)
FUNC <void cv.javaFeatureDetector.write [ARG String fileName=]>
java: void write(String fileName)
CLASS cv::.FastFeatureDetector : Feature2D
[CONST TYPE_5_8=0, CONST TYPE_7_12=1, CONST TYPE_9_16=2, CONST THRESHOLD=10000, CONST NONMAX_SUPPRESSION=10001, CONST FAST_N=10002]
FUNC <Ptr_FastFeatureDetector cv.FastFeatureDetector.create [ARG int threshold=10, ARG bool nonmaxSuppression=true, ARG int type=FastFeatureDetector::TYPE_9_16]>
java: FastFeatureDetector create(int threshold, boolean nonmaxSuppression, int type)
java: FastFeatureDetector create()
FUNC <String cv.FastFeatureDetector.getDefaultName []>
java: String getDefaultName()
FUNC <bool cv.FastFeatureDetector.getNonmaxSuppression []>
java: boolean getNonmaxSuppression()
FUNC <int cv.FastFeatureDetector.getThreshold []>
java: int getThreshold()
FUNC <int cv.FastFeatureDetector.getType []>
java: int getType()
FUNC <void cv.FastFeatureDetector.setNonmaxSuppression [ARG bool f=]>
java: void setNonmaxSuppression(boolean f)
FUNC <void cv.FastFeatureDetector.setThreshold [ARG int threshold=]>
java: void setThreshold(int threshold)
FUNC <void cv.FastFeatureDetector.setType [ARG int type=]>
java: void setType(int type)
CLASS cv::.Feature2D : Algorithm
FUNC <String cv.Feature2D.getDefaultName []>
java: String getDefaultName()
FUNC <bool cv.Feature2D.empty []>
java: boolean empty()
FUNC <int cv.Feature2D.defaultNorm []>
java: int defaultNorm()
FUNC <int cv.Feature2D.descriptorSize []>
java: int descriptorSize()
FUNC <int cv.Feature2D.descriptorType []>
java: int descriptorType()
FUNC <void cv.Feature2D.compute [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat descriptors=]>
java: void compute(Mat image, MatOfKeyPoint keypoints, Mat descriptors)
FUNC <void cv.Feature2D.compute [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat descriptors=]>
java: void compute(List<Mat> images, List<MatOfKeyPoint> keypoints, List<Mat> descriptors)
FUNC <void cv.Feature2D.detect [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat mask=Mat()]>
java: void detect(Mat image, MatOfKeyPoint keypoints, Mat mask)
java: void detect(Mat image, MatOfKeyPoint keypoints)
FUNC <void cv.Feature2D.detect [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat masks=vector_Mat()]>
java: void detect(List<Mat> images, List<MatOfKeyPoint> keypoints, List<Mat> masks)
java: void detect(List<Mat> images, List<MatOfKeyPoint> keypoints)
FUNC <void cv.Feature2D.detectAndCompute [ARG Mat image=, ARG Mat mask=, ARG vector_KeyPoint keypoints=, ARG Mat descriptors=, ARG bool useProvidedKeypoints=false]>
java: void detectAndCompute(Mat image, Mat mask, MatOfKeyPoint keypoints, Mat descriptors, boolean useProvidedKeypoints)
java: void detectAndCompute(Mat image, Mat mask, MatOfKeyPoint keypoints, Mat descriptors)
FUNC <void cv.Feature2D.read [ARG FileNode arg1=]>
SKIP:void read(FileNode arg1)	 due to ARG typeFileNode/I
FUNC <void cv.Feature2D.read [ARG String fileName=]>
java: void read(String fileName)
FUNC <void cv.Feature2D.write [ARG Ptr_FileStorage fs=, ARG String name=String()]>
SKIP:void write(Ptr_FileStorage fs, String name = String())	 due to ARG typePtr_FileStorage/I
FUNC <void cv.Feature2D.write [ARG String fileName=]>
java: void write(String fileName)
CLASS cv::.BRISK : Feature2D
FUNC <Ptr_BRISK cv.BRISK.create [ARG int thresh=, ARG int octaves=, ARG vector_float radiusList=, ARG vector_int numberList=, ARG float dMax=5.85f, ARG float dMin=8.2f, ARG vector_int indexChange=std::vector<int>()]>
java: BRISK create(int thresh, int octaves, MatOfFloat radiusList, MatOfInt numberList, float dMax, float dMin, MatOfInt indexChange)
java: BRISK create(int thresh, int octaves, MatOfFloat radiusList, MatOfInt numberList)
FUNC <Ptr_BRISK cv.BRISK.create [ARG int thresh=30, ARG int octaves=3, ARG float patternScale=1.0f]>
java: BRISK create(int thresh, int octaves, float patternScale)
java: BRISK create()
FUNC <Ptr_BRISK cv.BRISK.create [ARG vector_float radiusList=, ARG vector_int numberList=, ARG float dMax=5.85f, ARG float dMin=8.2f, ARG vector_int indexChange=std::vector<int>()]>
java: BRISK create(MatOfFloat radiusList, MatOfInt numberList, float dMax, float dMin, MatOfInt indexChange)
java: BRISK create(MatOfFloat radiusList, MatOfInt numberList)
FUNC <String cv.BRISK.getDefaultName []>
java: String getDefaultName()
CLASS cv::.BFMatcher : DescriptorMatcher
FUNC < cv.BFMatcher.BFMatcher [ARG int normType=NORM_L2, ARG bool crossCheck=false]>
java:  BFMatcher(int normType, boolean crossCheck)
java:  BFMatcher()
FUNC <Ptr_BFMatcher cv.BFMatcher.create [ARG int normType=NORM_L2, ARG bool crossCheck=false]>
java: BFMatcher create(int normType, boolean crossCheck)
java: BFMatcher create()
CLASS cv::.AgastFeatureDetector : Feature2D
[CONST AGAST_5_8=0, CONST AGAST_7_12d=1, CONST AGAST_7_12s=2, CONST OAST_9_16=3, CONST THRESHOLD=10000, CONST NONMAX_SUPPRESSION=10001]
FUNC <Ptr_AgastFeatureDetector cv.AgastFeatureDetector.create [ARG int threshold=10, ARG bool nonmaxSuppression=true, ARG int type=AgastFeatureDetector::OAST_9_16]>
java: AgastFeatureDetector create(int threshold, boolean nonmaxSuppression, int type)
java: AgastFeatureDetector create()
FUNC <String cv.AgastFeatureDetector.getDefaultName []>
java: String getDefaultName()
FUNC <bool cv.AgastFeatureDetector.getNonmaxSuppression []>
java: boolean getNonmaxSuppression()
FUNC <int cv.AgastFeatureDetector.getThreshold []>
java: int getThreshold()
FUNC <int cv.AgastFeatureDetector.getType []>
java: int getType()
FUNC <void cv.AgastFeatureDetector.setNonmaxSuppression [ARG bool f=]>
java: void setNonmaxSuppression(boolean f)
FUNC <void cv.AgastFeatureDetector.setThreshold [ARG int threshold=]>
java: void setThreshold(int threshold)
FUNC <void cv.AgastFeatureDetector.setType [ARG int type=]>
java: void setType(int type)
CLASS cv::.GFTTDetector : Feature2D
FUNC <Ptr_GFTTDetector cv.GFTTDetector.create [ARG int maxCorners=, ARG double qualityLevel=, ARG double minDistance=, ARG int blockSize=, ARG int gradiantSize=, ARG bool useHarrisDetector=false, ARG double k=0.04]>
java: GFTTDetector create(int maxCorners, double qualityLevel, double minDistance, int blockSize, int gradiantSize, boolean useHarrisDetector, double k)
java: GFTTDetector create(int maxCorners, double qualityLevel, double minDistance, int blockSize, int gradiantSize)
FUNC <Ptr_GFTTDetector cv.GFTTDetector.create [ARG int maxCorners=1000, ARG double qualityLevel=0.01, ARG double minDistance=1, ARG int blockSize=3, ARG bool useHarrisDetector=false, ARG double k=0.04]>
java: GFTTDetector create(int maxCorners, double qualityLevel, double minDistance, int blockSize, boolean useHarrisDetector, double k)
java: GFTTDetector create()
FUNC <String cv.GFTTDetector.getDefaultName []>
java: String getDefaultName()
FUNC <bool cv.GFTTDetector.getHarrisDetector []>
java: boolean getHarrisDetector()
FUNC <double cv.GFTTDetector.getK []>
java: double getK()
FUNC <double cv.GFTTDetector.getMinDistance []>
java: double getMinDistance()
FUNC <double cv.GFTTDetector.getQualityLevel []>
java: double getQualityLevel()
FUNC <int cv.GFTTDetector.getBlockSize []>
java: int getBlockSize()
FUNC <int cv.GFTTDetector.getMaxFeatures []>
java: int getMaxFeatures()
FUNC <void cv.GFTTDetector.setBlockSize [ARG int blockSize=]>
java: void setBlockSize(int blockSize)
FUNC <void cv.GFTTDetector.setHarrisDetector [ARG bool val=]>
java: void setHarrisDetector(boolean val)
FUNC <void cv.GFTTDetector.setK [ARG double k=]>
java: void setK(double k)
FUNC <void cv.GFTTDetector.setMaxFeatures [ARG int maxFeatures=]>
java: void setMaxFeatures(int maxFeatures)
FUNC <void cv.GFTTDetector.setMinDistance [ARG double minDistance=]>
java: void setMinDistance(double minDistance)
FUNC <void cv.GFTTDetector.setQualityLevel [ARG double qlevel=]>
java: void setQualityLevel(double qlevel)
CLASS cv::.DescriptorMatcher : Algorithm
[CONST FLANNBASED=1, CONST BRUTEFORCE=2, CONST BRUTEFORCE_L1=3, CONST BRUTEFORCE_HAMMING=4, CONST BRUTEFORCE_HAMMINGLUT=5, CONST BRUTEFORCE_SL2=6]
FUNC <Ptr_DescriptorMatcher cv.DescriptorMatcher.clone [ARG bool emptyTrainData=false]>
java: DescriptorMatcher clone(boolean emptyTrainData)
java: DescriptorMatcher clone()
FUNC <Ptr_DescriptorMatcher cv.DescriptorMatcher.create [ARG String descriptorMatcherType=]>
java: DescriptorMatcher create(String descriptorMatcherType)
FUNC <Ptr_DescriptorMatcher cv.DescriptorMatcher.create [ARG int matcherType=]>
java: DescriptorMatcher create(int matcherType)
FUNC <bool cv.DescriptorMatcher.empty []>
java: boolean empty()
FUNC <bool cv.DescriptorMatcher.isMaskSupported []>
java: boolean isMaskSupported()
FUNC <vector_Mat cv.DescriptorMatcher.getTrainDescriptors []>
java: List<Mat> getTrainDescriptors()
FUNC <void cv.DescriptorMatcher.add [ARG vector_Mat descriptors=]>
java: void add(List<Mat> descriptors)
FUNC <void cv.DescriptorMatcher.clear []>
java: void clear()
FUNC <void cv.DescriptorMatcher.knnMatch [ARG Mat queryDescriptors=, ARG Mat trainDescriptors=, ARG vector_vector_DMatch matches=, ARG int k=, ARG Mat mask=Mat(), ARG bool compactResult=false]>
java: void knnMatch(Mat queryDescriptors, Mat trainDescriptors, List<MatOfDMatch> matches, int k, Mat mask, boolean compactResult)
java: void knnMatch(Mat queryDescriptors, Mat trainDescriptors, List<MatOfDMatch> matches, int k)
FUNC <void cv.DescriptorMatcher.knnMatch [ARG Mat queryDescriptors=, ARG vector_vector_DMatch matches=, ARG int k=, ARG vector_Mat masks=vector_Mat(), ARG bool compactResult=false]>
java: void knnMatch(Mat queryDescriptors, List<MatOfDMatch> matches, int k, List<Mat> masks, boolean compactResult)
java: void knnMatch(Mat queryDescriptors, List<MatOfDMatch> matches, int k)
FUNC <void cv.DescriptorMatcher.match [ARG Mat queryDescriptors=, ARG Mat trainDescriptors=, ARG vector_DMatch matches=, ARG Mat mask=Mat()]>
java: void match(Mat queryDescriptors, Mat trainDescriptors, MatOfDMatch matches, Mat mask)
java: void match(Mat queryDescriptors, Mat trainDescriptors, MatOfDMatch matches)
FUNC <void cv.DescriptorMatcher.match [ARG Mat queryDescriptors=, ARG vector_DMatch matches=, ARG vector_Mat masks=vector_Mat()]>
java: void match(Mat queryDescriptors, MatOfDMatch matches, List<Mat> masks)
java: void match(Mat queryDescriptors, MatOfDMatch matches)
FUNC <void cv.DescriptorMatcher.radiusMatch [ARG Mat queryDescriptors=, ARG Mat trainDescriptors=, ARG vector_vector_DMatch matches=, ARG float maxDistance=, ARG Mat mask=Mat(), ARG bool compactResult=false]>
java: void radiusMatch(Mat queryDescriptors, Mat trainDescriptors, List<MatOfDMatch> matches, float maxDistance, Mat mask, boolean compactResult)
java: void radiusMatch(Mat queryDescriptors, Mat trainDescriptors, List<MatOfDMatch> matches, float maxDistance)
FUNC <void cv.DescriptorMatcher.radiusMatch [ARG Mat queryDescriptors=, ARG vector_vector_DMatch matches=, ARG float maxDistance=, ARG vector_Mat masks=vector_Mat(), ARG bool compactResult=false]>
java: void radiusMatch(Mat queryDescriptors, List<MatOfDMatch> matches, float maxDistance, List<Mat> masks, boolean compactResult)
java: void radiusMatch(Mat queryDescriptors, List<MatOfDMatch> matches, float maxDistance)
FUNC <void cv.DescriptorMatcher.read [ARG FileNode arg1=]>
SKIP:void read(FileNode arg1)	 due to ARG typeFileNode/I
FUNC <void cv.DescriptorMatcher.read [ARG String fileName=]>
java: void read(String fileName)
FUNC <void cv.DescriptorMatcher.train []>
java: void train()
FUNC <void cv.DescriptorMatcher.write [ARG Ptr_FileStorage fs=, ARG String name=String()]>
SKIP:void write(Ptr_FileStorage fs, String name = String())	 due to ARG typePtr_FileStorage/I
FUNC <void cv.DescriptorMatcher.write [ARG String fileName=]>
java: void write(String fileName)
CLASS cv::.KAZE : Feature2D
[CONST DIFF_PM_G1=0, CONST DIFF_PM_G2=1, CONST DIFF_WEICKERT=2, CONST DIFF_CHARBONNIER=3]
FUNC <Ptr_KAZE cv.KAZE.create [ARG bool extended=false, ARG bool upright=false, ARG float threshold=0.001f, ARG int nOctaves=4, ARG int nOctaveLayers=4, ARG int diffusivity=KAZE::DIFF_PM_G2]>
java: KAZE create(boolean extended, boolean upright, float threshold, int nOctaves, int nOctaveLayers, int diffusivity)
java: KAZE create()
FUNC <String cv.KAZE.getDefaultName []>
java: String getDefaultName()
FUNC <bool cv.KAZE.getExtended []>
java: boolean getExtended()
FUNC <bool cv.KAZE.getUpright []>
java: boolean getUpright()
FUNC <double cv.KAZE.getThreshold []>
java: double getThreshold()
FUNC <int cv.KAZE.getDiffusivity []>
java: int getDiffusivity()
FUNC <int cv.KAZE.getNOctaveLayers []>
java: int getNOctaveLayers()
FUNC <int cv.KAZE.getNOctaves []>
java: int getNOctaves()
FUNC <void cv.KAZE.setDiffusivity [ARG int diff=]>
java: void setDiffusivity(int diff)
FUNC <void cv.KAZE.setExtended [ARG bool extended=]>
java: void setExtended(boolean extended)
FUNC <void cv.KAZE.setNOctaveLayers [ARG int octaveLayers=]>
java: void setNOctaveLayers(int octaveLayers)
FUNC <void cv.KAZE.setNOctaves [ARG int octaves=]>
java: void setNOctaves(int octaves)
FUNC <void cv.KAZE.setThreshold [ARG double threshold=]>
java: void setThreshold(double threshold)
FUNC <void cv.KAZE.setUpright [ARG bool upright=]>
java: void setUpright(boolean upright)
CLASS ::.Features2d : 
[CONST DRAW_OVER_OUTIMG=1, CONST NOT_DRAW_SINGLE_POINTS=2, CONST DRAW_RICH_KEYPOINTS=4]
FUNC <void cv..drawKeypoints [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat outImage=, ARG Scalar color=Scalar::all(-1), ARG int flags=DrawMatchesFlags::DEFAULT]>
java: void drawKeypoints(Mat image, MatOfKeyPoint keypoints, Mat outImage, Scalar color, int flags)
java: void drawKeypoints(Mat image, MatOfKeyPoint keypoints, Mat outImage)
FUNC <void cv..drawMatches [ARG Mat img1=, ARG vector_KeyPoint keypoints1=, ARG Mat img2=, ARG vector_KeyPoint keypoints2=, ARG vector_DMatch matches1to2=, ARG Mat outImg=, ARG Scalar matchColor=Scalar::all(-1), ARG Scalar singlePointColor=Scalar::all(-1), ARG vector_char matchesMask=std::vector<char>(), ARG int flags=DrawMatchesFlags::DEFAULT]>
java: void drawMatches(Mat img1, MatOfKeyPoint keypoints1, Mat img2, MatOfKeyPoint keypoints2, MatOfDMatch matches1to2, Mat outImg, Scalar matchColor, Scalar singlePointColor, MatOfByte matchesMask, int flags)
java: void drawMatches(Mat img1, MatOfKeyPoint keypoints1, Mat img2, MatOfKeyPoint keypoints2, MatOfDMatch matches1to2, Mat outImg)
FUNC <void cv..drawMatches [ARG Mat img1=, ARG vector_KeyPoint keypoints1=, ARG Mat img2=, ARG vector_KeyPoint keypoints2=, ARG vector_vector_DMatch matches1to2=, ARG Mat outImg=, ARG Scalar matchColor=Scalar::all(-1), ARG Scalar singlePointColor=Scalar::all(-1), ARG vector_vector_char matchesMask=std::vector<std::vector<char> >(), ARG int flags=0]>
java: void drawMatches2(Mat img1, MatOfKeyPoint keypoints1, Mat img2, MatOfKeyPoint keypoints2, List<MatOfDMatch> matches1to2, Mat outImg, Scalar matchColor, Scalar singlePointColor, List<MatOfByte> matchesMask, int flags)
java: void drawMatches2(Mat img1, MatOfKeyPoint keypoints1, Mat img2, MatOfKeyPoint keypoints2, List<MatOfDMatch> matches1to2, Mat outImg)
FUNC <void cv..drawMatches [ARG Mat img1=, ARG vector_KeyPoint keypoints1=, ARG Mat img2=, ARG vector_KeyPoint keypoints2=, ARG vector_vector_DMatch matches1to2=, ARG Mat outImg=, ARG Scalar matchColor=Scalar::all(-1), ARG Scalar singlePointColor=Scalar::all(-1), ARG vector_vector_char matchesMask=std::vector<std::vector<char> >(), ARG int flags=DrawMatchesFlags::DEFAULT]>
java: void drawMatchesKnn(Mat img1, MatOfKeyPoint keypoints1, Mat img2, MatOfKeyPoint keypoints2, List<MatOfDMatch> matches1to2, Mat outImg, Scalar matchColor, Scalar singlePointColor, List<MatOfByte> matchesMask, int flags)
java: void drawMatchesKnn(Mat img1, MatOfKeyPoint keypoints1, Mat img2, MatOfKeyPoint keypoints2, List<MatOfDMatch> matches1to2, Mat outImg)
CLASS cv::.AKAZE : Feature2D
[CONST DESCRIPTOR_KAZE_UPRIGHT=2, CONST DESCRIPTOR_KAZE=3, CONST DESCRIPTOR_MLDB_UPRIGHT=4, CONST DESCRIPTOR_MLDB=5]
FUNC <Ptr_AKAZE cv.AKAZE.create [ARG int descriptor_type=AKAZE::DESCRIPTOR_MLDB, ARG int descriptor_size=0, ARG int descriptor_channels=3, ARG float threshold=0.001f, ARG int nOctaves=4, ARG int nOctaveLayers=4, ARG int diffusivity=KAZE::DIFF_PM_G2]>
java: AKAZE create(int descriptor_type, int descriptor_size, int descriptor_channels, float threshold, int nOctaves, int nOctaveLayers, int diffusivity)
java: AKAZE create()
FUNC <String cv.AKAZE.getDefaultName []>
java: String getDefaultName()
FUNC <double cv.AKAZE.getThreshold []>
java: double getThreshold()
FUNC <int cv.AKAZE.getDescriptorChannels []>
java: int getDescriptorChannels()
FUNC <int cv.AKAZE.getDescriptorSize []>
java: int getDescriptorSize()
FUNC <int cv.AKAZE.getDescriptorType []>
java: int getDescriptorType()
FUNC <int cv.AKAZE.getDiffusivity []>
java: int getDiffusivity()
FUNC <int cv.AKAZE.getNOctaveLayers []>
java: int getNOctaveLayers()
FUNC <int cv.AKAZE.getNOctaves []>
java: int getNOctaves()
FUNC <void cv.AKAZE.setDescriptorChannels [ARG int dch=]>
java: void setDescriptorChannels(int dch)
FUNC <void cv.AKAZE.setDescriptorSize [ARG int dsize=]>
java: void setDescriptorSize(int dsize)
FUNC <void cv.AKAZE.setDescriptorType [ARG int dtype=]>
java: void setDescriptorType(int dtype)
FUNC <void cv.AKAZE.setDiffusivity [ARG int diff=]>
java: void setDiffusivity(int diff)
FUNC <void cv.AKAZE.setNOctaveLayers [ARG int octaveLayers=]>
java: void setNOctaveLayers(int octaveLayers)
FUNC <void cv.AKAZE.setNOctaves [ARG int octaves=]>
java: void setNOctaves(int octaves)
FUNC <void cv.AKAZE.setThreshold [ARG double threshold=]>
java: void setThreshold(double threshold)
CLASS cv::SimpleBlobDetector.Params : 
FUNC < cv.SimpleBlobDetector.Params.Params []>
java:  Params()
FUNC <float cv.SimpleBlobDetector.Params.get_thresholdStep []>
java: float get_thresholdStep()
FUNC <void cv.SimpleBlobDetector.Params.set_thresholdStep [ARG float thresholdStep=]>
java: void set_thresholdStep(float thresholdStep)
FUNC <float cv.SimpleBlobDetector.Params.get_minThreshold []>
java: float get_minThreshold()
FUNC <void cv.SimpleBlobDetector.Params.set_minThreshold [ARG float minThreshold=]>
java: void set_minThreshold(float minThreshold)
FUNC <float cv.SimpleBlobDetector.Params.get_maxThreshold []>
java: float get_maxThreshold()
FUNC <void cv.SimpleBlobDetector.Params.set_maxThreshold [ARG float maxThreshold=]>
java: void set_maxThreshold(float maxThreshold)
FUNC <size_t cv.SimpleBlobDetector.Params.get_minRepeatability []>
java: long get_minRepeatability()
FUNC <void cv.SimpleBlobDetector.Params.set_minRepeatability [ARG size_t minRepeatability=]>
java: void set_minRepeatability(long minRepeatability)
FUNC <float cv.SimpleBlobDetector.Params.get_minDistBetweenBlobs []>
java: float get_minDistBetweenBlobs()
FUNC <void cv.SimpleBlobDetector.Params.set_minDistBetweenBlobs [ARG float minDistBetweenBlobs=]>
java: void set_minDistBetweenBlobs(float minDistBetweenBlobs)
FUNC <bool cv.SimpleBlobDetector.Params.get_filterByColor []>
java: boolean get_filterByColor()
FUNC <void cv.SimpleBlobDetector.Params.set_filterByColor [ARG bool filterByColor=]>
java: void set_filterByColor(boolean filterByColor)
FUNC <uchar cv.SimpleBlobDetector.Params.get_blobColor []>
SKIP:uchar Params::blobColor	 due to RET typeuchar
FUNC <void cv.SimpleBlobDetector.Params.set_blobColor [ARG uchar blobColor=]>
SKIP:void Params::blobColor	 due to ARG typeuchar/I
FUNC <bool cv.SimpleBlobDetector.Params.get_filterByArea []>
java: boolean get_filterByArea()
FUNC <void cv.SimpleBlobDetector.Params.set_filterByArea [ARG bool filterByArea=]>
java: void set_filterByArea(boolean filterByArea)
FUNC <float cv.SimpleBlobDetector.Params.get_minArea []>
java: float get_minArea()
FUNC <void cv.SimpleBlobDetector.Params.set_minArea [ARG float minArea=]>
java: void set_minArea(float minArea)
FUNC <float cv.SimpleBlobDetector.Params.get_maxArea []>
java: float get_maxArea()
FUNC <void cv.SimpleBlobDetector.Params.set_maxArea [ARG float maxArea=]>
java: void set_maxArea(float maxArea)
FUNC <bool cv.SimpleBlobDetector.Params.get_filterByCircularity []>
java: boolean get_filterByCircularity()
FUNC <void cv.SimpleBlobDetector.Params.set_filterByCircularity [ARG bool filterByCircularity=]>
java: void set_filterByCircularity(boolean filterByCircularity)
FUNC <float cv.SimpleBlobDetector.Params.get_minCircularity []>
java: float get_minCircularity()
FUNC <void cv.SimpleBlobDetector.Params.set_minCircularity [ARG float minCircularity=]>
java: void set_minCircularity(float minCircularity)
FUNC <float cv.SimpleBlobDetector.Params.get_maxCircularity []>
java: float get_maxCircularity()
FUNC <void cv.SimpleBlobDetector.Params.set_maxCircularity [ARG float maxCircularity=]>
java: void set_maxCircularity(float maxCircularity)
FUNC <bool cv.SimpleBlobDetector.Params.get_filterByInertia []>
java: boolean get_filterByInertia()
FUNC <void cv.SimpleBlobDetector.Params.set_filterByInertia [ARG bool filterByInertia=]>
java: void set_filterByInertia(boolean filterByInertia)
FUNC <float cv.SimpleBlobDetector.Params.get_minInertiaRatio []>
java: float get_minInertiaRatio()
FUNC <void cv.SimpleBlobDetector.Params.set_minInertiaRatio [ARG float minInertiaRatio=]>
java: void set_minInertiaRatio(float minInertiaRatio)
FUNC <float cv.SimpleBlobDetector.Params.get_maxInertiaRatio []>
java: float get_maxInertiaRatio()
FUNC <void cv.SimpleBlobDetector.Params.set_maxInertiaRatio [ARG float maxInertiaRatio=]>
java: void set_maxInertiaRatio(float maxInertiaRatio)
FUNC <bool cv.SimpleBlobDetector.Params.get_filterByConvexity []>
java: boolean get_filterByConvexity()
FUNC <void cv.SimpleBlobDetector.Params.set_filterByConvexity [ARG bool filterByConvexity=]>
java: void set_filterByConvexity(boolean filterByConvexity)
FUNC <float cv.SimpleBlobDetector.Params.get_minConvexity []>
java: float get_minConvexity()
FUNC <void cv.SimpleBlobDetector.Params.set_minConvexity [ARG float minConvexity=]>
java: void set_minConvexity(float minConvexity)
FUNC <float cv.SimpleBlobDetector.Params.get_maxConvexity []>
java: float get_maxConvexity()
FUNC <void cv.SimpleBlobDetector.Params.set_maxConvexity [ARG float maxConvexity=]>
java: void set_maxConvexity(float maxConvexity)
CLASS cv::.BOWTrainer : 
FUNC <Mat cv.BOWTrainer.cluster [ARG Mat descriptors=]>
java: Mat cluster(Mat descriptors)
FUNC <Mat cv.BOWTrainer.cluster []>
java: Mat cluster()
FUNC <int cv.BOWTrainer.descriptorsCount []>
java: int descriptorsCount()
FUNC <vector_Mat cv.BOWTrainer.getDescriptors []>
java: List<Mat> getDescriptors()
FUNC <void cv.BOWTrainer.add [ARG Mat descriptors=]>
java: void add(Mat descriptors)
FUNC <void cv.BOWTrainer.clear []>
java: void clear()
CLASS cv::.javaDescriptorExtractor : 
[CONST OPPONENTEXTRACTOR=1000]
[CONST SIFT=1, CONST SURF=2, CONST ORB=3, CONST BRIEF=4, CONST BRISK=5, CONST FREAK=6, CONST AKAZE=7, CONST OPPONENT_SIFT=OPPONENTEXTRACTOR + SIFT, CONST OPPONENT_SURF=OPPONENTEXTRACTOR + SURF, CONST OPPONENT_ORB=OPPONENTEXTRACTOR + ORB, CONST OPPONENT_BRIEF=OPPONENTEXTRACTOR + BRIEF, CONST OPPONENT_BRISK=OPPONENTEXTRACTOR + BRISK, CONST OPPONENT_FREAK=OPPONENTEXTRACTOR + FREAK, CONST OPPONENT_AKAZE=OPPONENTEXTRACTOR + AKAZE]
FUNC <Ptr_javaDescriptorExtractor cv.javaDescriptorExtractor.create [ARG int extractorType=]>
java: DescriptorExtractor create(int extractorType)
FUNC <bool cv.javaDescriptorExtractor.empty []>
java: boolean empty()
FUNC <int cv.javaDescriptorExtractor.descriptorSize []>
java: int descriptorSize()
FUNC <int cv.javaDescriptorExtractor.descriptorType []>
java: int descriptorType()
FUNC <void cv.javaDescriptorExtractor.compute [ARG Mat image=, ARG vector_KeyPoint keypoints=, ARG Mat descriptors=]>
java: void compute(Mat image, MatOfKeyPoint keypoints, Mat descriptors)
FUNC <void cv.javaDescriptorExtractor.compute [ARG vector_Mat images=, ARG vector_vector_KeyPoint keypoints=, ARG vector_Mat descriptors=]>
java: void compute(List<Mat> images, List<MatOfKeyPoint> keypoints, List<Mat> descriptors)
FUNC <void cv.javaDescriptorExtractor.read [ARG String fileName=]>
java: void read(String fileName)
FUNC <void cv.javaDescriptorExtractor.write [ARG String fileName=]>
java: void write(String fileName)
CLASS cv::.ORB : Feature2D
[CONST kBytes=32, CONST HARRIS_SCORE=0, CONST FAST_SCORE=1]
FUNC <Ptr_ORB cv.ORB.create [ARG int nfeatures=500, ARG float scaleFactor=1.2f, ARG int nlevels=8, ARG int edgeThreshold=31, ARG int firstLevel=0, ARG int WTA_K=2, ARG int scoreType=ORB::HARRIS_SCORE, ARG int patchSize=31, ARG int fastThreshold=20]>
java: ORB create(int nfeatures, float scaleFactor, int nlevels, int edgeThreshold, int firstLevel, int WTA_K, int scoreType, int patchSize, int fastThreshold)
java: ORB create()
FUNC <String cv.ORB.getDefaultName []>
java: String getDefaultName()
FUNC <double cv.ORB.getScaleFactor []>
java: double getScaleFactor()
FUNC <int cv.ORB.getEdgeThreshold []>
java: int getEdgeThreshold()
FUNC <int cv.ORB.getFastThreshold []>
java: int getFastThreshold()
FUNC <int cv.ORB.getFirstLevel []>
java: int getFirstLevel()
FUNC <int cv.ORB.getMaxFeatures []>
java: int getMaxFeatures()
FUNC <int cv.ORB.getNLevels []>
java: int getNLevels()
FUNC <int cv.ORB.getPatchSize []>
java: int getPatchSize()
FUNC <int cv.ORB.getScoreType []>
java: int getScoreType()
FUNC <int cv.ORB.getWTA_K []>
java: int getWTA_K()
FUNC <void cv.ORB.setEdgeThreshold [ARG int edgeThreshold=]>
java: void setEdgeThreshold(int edgeThreshold)
FUNC <void cv.ORB.setFastThreshold [ARG int fastThreshold=]>
java: void setFastThreshold(int fastThreshold)
FUNC <void cv.ORB.setFirstLevel [ARG int firstLevel=]>
java: void setFirstLevel(int firstLevel)
FUNC <void cv.ORB.setMaxFeatures [ARG int maxFeatures=]>
java: void setMaxFeatures(int maxFeatures)
FUNC <void cv.ORB.setNLevels [ARG int nlevels=]>
java: void setNLevels(int nlevels)
FUNC <void cv.ORB.setPatchSize [ARG int patchSize=]>
java: void setPatchSize(int patchSize)
FUNC <void cv.ORB.setScaleFactor [ARG double scaleFactor=]>
java: void setScaleFactor(double scaleFactor)
FUNC <void cv.ORB.setScoreType [ARG int scoreType=]>
java: void setScoreType(int scoreType)
FUNC <void cv.ORB.setWTA_K [ARG int wta_k=]>
java: void setWTA_K(int wta_k)
CLASS cv::.MSER : Feature2D
FUNC <Ptr_MSER cv.MSER.create [ARG int _delta=5, ARG int _min_area=60, ARG int _max_area=14400, ARG double _max_variation=0.25, ARG double _min_diversity=.2, ARG int _max_evolution=200, ARG double _area_threshold=1.01, ARG double _min_margin=0.003, ARG int _edge_blur_size=5]>
java: MSER create(int _delta, int _min_area, int _max_area, double _max_variation, double _min_diversity, int _max_evolution, double _area_threshold, double _min_margin, int _edge_blur_size)
java: MSER create()
FUNC <String cv.MSER.getDefaultName []>
java: String getDefaultName()
FUNC <bool cv.MSER.getPass2Only []>
java: boolean getPass2Only()
FUNC <int cv.MSER.getDelta []>
java: int getDelta()
FUNC <int cv.MSER.getMaxArea []>
java: int getMaxArea()
FUNC <int cv.MSER.getMinArea []>
java: int getMinArea()
FUNC <void cv.MSER.detectRegions [ARG Mat image=, ARG vector_vector_Point msers=, ARG vector_Rect bboxes=]>
java: void detectRegions(Mat image, List<MatOfPoint> msers, MatOfRect bboxes)
FUNC <void cv.MSER.setDelta [ARG int delta=]>
java: void setDelta(int delta)
FUNC <void cv.MSER.setMaxArea [ARG int maxArea=]>
java: void setMaxArea(int maxArea)
FUNC <void cv.MSER.setMinArea [ARG int minArea=]>
java: void setMinArea(int minArea)
FUNC <void cv.MSER.setPass2Only [ARG bool f=]>
java: void setPass2Only(boolean f)
CLASS cv::.BOWKMeansTrainer : BOWTrainer
FUNC < cv.BOWKMeansTrainer.BOWKMeansTrainer [ARG int clusterCount=, ARG TermCriteria termcrit=TermCriteria(), ARG int attempts=3, ARG int flags=KMEANS_PP_CENTERS]>
java:  BOWKMeansTrainer(int clusterCount, TermCriteria termcrit, int attempts, int flags)
java:  BOWKMeansTrainer(int clusterCount)
FUNC <Mat cv.BOWKMeansTrainer.cluster [ARG Mat descriptors=]>
java: Mat cluster(Mat descriptors)
FUNC <Mat cv.BOWKMeansTrainer.cluster []>
java: Mat cluster()
CLASS cv::.FlannBasedMatcher : DescriptorMatcher
FUNC < cv.FlannBasedMatcher.FlannBasedMatcher [ARG Ptr_flann_IndexParams indexParams=makePtr<flann::KDTreeIndexParams>(), ARG Ptr_flann_SearchParams searchParams=makePtr<flann::SearchParams>()]>
java:  FlannBasedMatcher()
java:  FlannBasedMatcher()
FUNC <Ptr_FlannBasedMatcher cv.FlannBasedMatcher.create []>
java: FlannBasedMatcher create()
